{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 144,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "import nltk\n",
    "from nltk.stem import PorterStemmer\n",
    "## To be executed once\n",
    "# nltk.download('punkt')\n",
    "# nltk.download('stopwords')\n",
    "import re\n",
    "import pickle\n",
    "import time\n",
    "from colorama import Fore, Back, Style\n",
    "\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from sklearn.naive_bayes import MultinomialNB\n",
    "from sklearn import metrics\n",
    "\n",
    "\n",
    "import urllib.request\n",
    "import webbrowser"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 145,
   "metadata": {},
   "outputs": [],
   "source": [
    "from nltk.corpus import stopwords\n",
    "#quit_words = ['quit', 'bye', 'thanks', 'exit', 'thankyou', 'thank you', 'thanku']\n",
    "# sanjay\n",
    "quit_words = ['quit', 'bye', 'thanks', 'exit', 'thankyou', 'thanku', 'goodbye', 'later', 'laters', \"sayonara\"]\n",
    "\n",
    "greetings = [\"hello\",\"hey\",\"hi\",\"hello\",\"howareyou\",\"bot\"\n",
    "                 \"howsitgoing\",\"help\",\"ineedsomehelp\",\"ineedhelp\",\n",
    "                 \"hithere\",\"hellothere\",\"hichatbot\",\"higreatlearning\",\n",
    "                 \"higreatlearning\",\"anybodythere\",\"areyouachatbot\",\n",
    "                 \"areyouhuman\",\"greetings\",\"nicetomeetyou\",\"whatsup\",\n",
    "                 \"goodmorning\",\"goodafternoon\",\"goodevening\",\n",
    "                 \"goodnight\",\"areyoureal\",\"youreamachine\",\"tellmesomething\",\n",
    "                 \"whatcanyoudo\",\"howcanyouhelpme\",\"ihaveaquestion\",\n",
    "                 \"canyouhelpme\",\"whatsyourname\",\"greetingsbot\",\"morning\",\n",
    "                 \"afternoon\",\"hellochatbot\",\"check\",\"test\",\"howdy\",\n",
    "                 \"morning\",\"afternoon\",\"evening\",\"heyman\",\"howsyourdaygoing\"\n",
    "                 \"itsbeenawhile\",\"howareyoudoing\",\"sup\",\"whatsgoingon\",\n",
    "                 \"howseverything\",\"howarethings\",\"howslife\",\"howsyourday\"\n",
    "                 \"goodtoseeyou\",\"nicetoseeyou\",\"longtimenosee\",\n",
    "                 \"pleasedtomeetyou\",\"itsnicetomeetyou\",\"howhaveyoubeen\",\n",
    "                 \"howdoyoudo\",\"yo\",\"heymate\",\"whazzup\",\"gdaymate\",\n",
    "                 \"hiya\",\"ok\",\"cool\"\n",
    "            ]\n",
    "\n",
    "fallback_messages = [\"Sorry, I don't quite understand that. Please try rephrasing your command.\",\n",
    "                     \"Oops! I didn’t get that\", \n",
    "                     \"I have never heard that before. Not sure how to respond to that.\",\n",
    "                     \"Sorry, I didn't get that. Can you say that a different way ?\",\n",
    "                     \"Sorry but I don’t know the answer to that. Try asking me something else.\",\n",
    "                     \"Sorry I am currently not trained for this question.\"]\n",
    "\n",
    "# root to be used as random state\n",
    "root = 42"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 152,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Spelling correction\n",
    "import re\n",
    "from collections import Counter\n",
    "\n",
    "def words(text): return re.findall(r'\\w+', text.lower())\n",
    "\n",
    "WORDS = Counter(words(open('big_ml.txt', encoding=\"utf8\").read()))\n",
    "\n",
    "def P(word, N=sum(WORDS.values())): \n",
    "    \"Probability of `word`.\"\n",
    "    return WORDS[word] / N\n",
    "\n",
    "def correction(word): \n",
    "    \"Most probable spelling correction for word.\"\n",
    "    return max(candidates(word), key=P)\n",
    "\n",
    "def candidates(word): \n",
    "    \"Generate possible spelling corrections for word.\"\n",
    "    return (known([word]) or known(edits1(word)) or known(edits2(word)) or [word])\n",
    "\n",
    "def known(words): \n",
    "    \"The subset of `words` that appear in the dictionary of WORDS.\"\n",
    "    return set(w for w in words if w in WORDS)\n",
    "\n",
    "def edits1(word):\n",
    "    \"All edits that are one edit away from `word`.\"\n",
    "    letters    = 'abcdefghijklmnopqrstuvwxyz'\n",
    "    splits     = [(word[:i], word[i:])    for i in range(len(word) + 1)]\n",
    "    deletes    = [L + R[1:]               for L, R in splits if R]\n",
    "    transposes = [L + R[1] + R[0] + R[2:] for L, R in splits if len(R)>1]\n",
    "    replaces   = [L + c + R[1:]           for L, R in splits if R for c in letters]\n",
    "    inserts    = [L + c + R               for L, R in splits for c in letters]\n",
    "    return set(deletes + transposes + replaces + inserts)\n",
    "\n",
    "def edits2(word): \n",
    "    \"All edits that are two edits away from `word`.\"\n",
    "    return (e2 for e1 in edits1(word) for e2 in edits1(e1))\n",
    "\n",
    "def print_fallback_message(i):\n",
    "    num_of_msgs = len(fallback_messages)\n",
    "    idx = i % num_of_msgs\n",
    "    print(fallback_messages[idx])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 147,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # speling correction new code\n",
    "# import re, collections, math\n",
    "# import re \n",
    "# from collections import Counter\n",
    "\n",
    "# def words(text): return re.findall('[a-z]+', text.lower())\n",
    "\n",
    "# WORDS = Counter(words(open('big_ml.txt', encoding=\"utf8\").read()))\n",
    "\n",
    "# def P(word, N=sum(WORDS.values())): \n",
    "#     \"Probability of `word`.\"\n",
    "#     return WORDS[word] / N\n",
    "\n",
    "# def valid(w):\n",
    "#   return all(s in WORDS for s in w.split())\n",
    "\n",
    "# def correction(word): \n",
    "#     \"Most probable spelling correction for word.\"\n",
    "#     return max(candidates(word), key=P)\n",
    "\n",
    "# def candidates(word): \n",
    "#     \"Generate possible spelling corrections for word.\"\n",
    "#     return (known([word]) or known(edits1(word)) or known(edits2(word)) or known(justsplit1(word)) or [word])\n",
    "\n",
    "# alphabet = 'abcdefghijklmnopqrstuvwxyz '\n",
    "\n",
    "# def known(words): return set(w for w in words if valid(w))\n",
    "\n",
    "# def edits1(word):\n",
    "#   splits     = [(word[:i], word[i:]) for i in range(len(word) + 1)]\n",
    "#   deletes    = [a + b[1:] for a, b in splits if b]\n",
    "#   transposes = [a + b[1] + b[0] + b[2:] for a, b in splits if len(b)>1]\n",
    "#   replaces   = [a + c + b[1:] for a, b in splits for c in alphabet if b]\n",
    "#   inserts    = [a + c + b     for a, b in splits for c in alphabet]\n",
    "#   return set(deletes + transposes + replaces + inserts)\n",
    "\n",
    "# def edits2(word): \n",
    "#     \"All edits that are two edits away from `word`.\"\n",
    "#     return (e2 for e1 in edits1(word) for e2 in edits1(e1))\n",
    "\n",
    "# def justsplit1(word):\n",
    "#     \"All edits that are one edit away from `word`.\"\n",
    "#     splits     = [(word[:i], word[i:])    for i in range(len(word) + 1)]\n",
    "#     #deletes    = [L + R[1:]               for L, R in splits if R]\n",
    "#     deletes    = [L               for L, R in splits if R]\n",
    "#     deletes1    = [R               for L, R in splits if R]\n",
    "#     return set(deletes + deletes1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 181,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Common functions definition\n",
    "\n",
    "def cleanText(s1):\n",
    "#    print(\"Inside cleanText for:\", s1)  ##debug\n",
    "    ps = PorterStemmer()\n",
    "    text = s1.lower()\n",
    "    text = re.sub(r'[0-9]*','',text)\n",
    "    text = re.sub(\"[#$%&*@?><:\\\"]+\",'',text)\n",
    "    text = re.sub(r'\\s\\s+',' ',text)\n",
    "    word_list = []\n",
    "    for word in nltk.word_tokenize(text):\n",
    "        \n",
    "#        print(\"Original word:\", word)  ## debug print\n",
    "        word = correction(word)\n",
    "#        print(\"corrected word:\", word)  ##debug print\n",
    "        if(word not in stopwords.words('english')):\n",
    "            ps.stem(word)\n",
    "            word_list.append(word)\n",
    "    text = word_list\n",
    "#    print('from clean text:', word_list)  ## debug\n",
    "    text = ' '.join(text)\n",
    "#    print(\"Final sentence:\", text)  ## debug print\n",
    "    return text\n",
    "\n",
    "# After prediction convert tag to response\n",
    "def getResponse(tag):\n",
    "    try:\n",
    "        if(resp_dict[tag]):\n",
    "            response = resp_dict[tag]\n",
    "            return response\n",
    "        else:\n",
    "            print('Response not found.. Please try another query.')\n",
    "    except:\n",
    "        print('Response not found for:', tag)\n",
    "        print('I will update my knowledge soon :)')\n",
    "\n",
    "def process_response(response):\n",
    "    if(response[0:4]=='Link'):\n",
    "        url = response[5:]\n",
    "#        webbrowser.open(url)\n",
    "        print(\"Bot: Please check this link {}\".format(url))\n",
    "    else:\n",
    "        print(\"Bot: \", response)\n",
    "\n",
    "def store_new_query(query):\n",
    "#    print(\"Inside store_new_query function\")  ##debug\n",
    "    with open(\"non_corpus_queries.txt\", \"a\") as f:\n",
    "        str = inp_text + \"\\n\"\n",
    "        f.write(str)\n",
    "#SANJAY\n",
    "def clean_greeting(user_input: str):\n",
    "#    print(\"Inside clean_greeting function:\", user_input)  ##debug\n",
    "    \n",
    "    ps = PorterStemmer()\n",
    "    text = user_input.lower()\n",
    "    text = re.sub(r'[0-9]*','',text)\n",
    "    text = re.sub(\"[#$%&*@?><:\\\"]+\",'',text)\n",
    "    text = re.sub(r'\\s\\s+',' ',text)\n",
    "    word_list = []\n",
    "    for word in nltk.word_tokenize(text):\n",
    "        word = correction(word)\n",
    "        ps.stem(word)\n",
    "        word_list.append(word)\n",
    "    text = word_list\n",
    "    text = ' '.join(text)\n",
    "\n",
    "    cleaned_word = text\n",
    "    remove_spl_char = ''.join(e for e in cleaned_word if e.isalnum())\n",
    "    return ''.join([i for i in remove_spl_char if not i.isdigit()]) \n",
    "\n",
    "def print_fallback_message(i): \n",
    "    num_of_msgs = len(fallback_messages) \n",
    "    idx = i % num_of_msgs \n",
    "    print(fallback_messages[idx])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 149,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv(\"Corpus_1.csv\")\n",
    "df.columns = ['query', 'response', 'tag']\n",
    "df = df.dropna()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 150,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>query</th>\n",
       "      <th>response</th>\n",
       "      <th>tag</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>0</td>\n",
       "      <td>What is linear regression</td>\n",
       "      <td>Link:https://en.wikipedia.org/wiki/Linear_regr...</td>\n",
       "      <td>linear regression</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>Can you explain linear regression</td>\n",
       "      <td>Link:https://en.wikipedia.org/wiki/Linear_regr...</td>\n",
       "      <td>linear regression</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                               query  \\\n",
       "0          What is linear regression   \n",
       "1  Can you explain linear regression   \n",
       "\n",
       "                                            response                tag  \n",
       "0  Link:https://en.wikipedia.org/wiki/Linear_regr...  linear regression  \n",
       "1  Link:https://en.wikipedia.org/wiki/Linear_regr...  linear regression  "
      ]
     },
     "execution_count": 150,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 182,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Final sentence: linear regression\n",
      "Final sentence: explain linear regression\n",
      "Final sentence: please provide linear regression example\n",
      "Final sentence: apply linear regression\n",
      "Final sentence: mean linear regression\n",
      "Final sentence: unable understand linear regression\n",
      "Final sentence: knn formula\n",
      "Final sentence: knn\n",
      "Final sentence: explain knn\n",
      "Final sentence: please provide knn example\n",
      "Final sentence: apply knn\n",
      "Final sentence: mean knn\n",
      "Final sentence: libraries used machine learning\n",
      "Final sentence: library use build models\n",
      "Final sentence: neural networks\n",
      "Final sentence: use neural networks\n",
      "Final sentence: please explain neural networks\n",
      "Final sentence: using neural networks\n",
      "Final sentence: different kind neural networks\n",
      "Final sentence: prediction neural network\n",
      "Final sentence: select features\n",
      "Final sentence: feature selection\n",
      "Final sentence: choose features\n",
      "Final sentence: choosing features logistic regression\n",
      "Final sentence: feature selection classification\n",
      "Final sentence: select features naivebayes\n",
      "Final sentence: build random forest model classification\n",
      "Final sentence: get random forest\n",
      "Final sentence: understand random forest algorithm\n",
      "Final sentence: please explain ensemble random forest\n",
      "Final sentence: want know random forest\n",
      "Final sentence: decision trees\n",
      "Final sentence: explain decision trees\n",
      "Final sentence: explain decision trees\n",
      "Final sentence: please provide example decision trees\n",
      "Final sentence: decision tree works\n",
      "Final sentence: explain recurrent neural network\n",
      "Final sentence: lstm\n",
      "Final sentence: linear regression simple terms\n",
      "Final sentence: calculate linear regression\n",
      "Final sentence: linear regression work\n",
      "Final sentence: linear regression used\n",
      "Final sentence: examples linear regression\n",
      "Final sentence: explain linear regression child\n",
      "Final sentence: called linear regression\n",
      "Final sentence: multiple regression linear\n",
      "Final sentence: b linear regression\n",
      "Final sentence: linear regression always straight line\n",
      "Final sentence: multiple linear regression tell\n",
      "Final sentence: interpret linear regression\n",
      "Final sentence: four assumptions linear regression\n",
      "Final sentence: use multiple regression\n",
      "Final sentence: data suitable linear regression\n",
      "Final sentence: types regression\n",
      "Final sentence: r squared mean\n",
      "Final sentence: calculate regression\n",
      "Final sentence: linear regression example\n",
      "Final sentence: multiple linear regression\n",
      "Final sentence: linear regression algorithm\n",
      "Final sentence: logistic regression\n",
      "Final sentence: linear regression dummies\n",
      "Final sentence: linear regression equation\n",
      "Final sentence: regression analysis\n",
      "Final sentence: sklearn linear regression\n",
      "Final sentence: linear regression linear approach modeling\n",
      "Final sentence: linear regression established relationship scalar response explanatory variables\n",
      "Final sentence: one explanatory variable called simple linear regression\n",
      "Final sentence: one explanatory variable called multiple linear regression\n",
      "Final sentence: multivariate linear regression deals prediction multiple correlated dependent variables\n",
      "Final sentence: relationships modeled using linear predictor functions whose unknown model parameters estimated data\n",
      "Final sentence: linear regression focuses conditional probability distribution response given values predictors\n",
      "Final sentence: linear regression used goal prediction forecasting error reduction\n",
      "Final sentence: linear regression analysis applied quantify strength relationship response explanatory variables\n",
      "Final sentence: linear regression models often fitted using least squares approach\n",
      "Final sentence: linear regression minimizes lack fit\n",
      "Final sentence: linear regression minimizes penalized version least squares cost function ridge regression\n",
      "Final sentence: assumptions made standard linear regression models standard estimation techniques\n",
      "Final sentence: ordinary least squares\n",
      "Final sentence: ols\n",
      "Final sentence: weak exogeneity\n",
      "Final sentence: linearity\n",
      "Final sentence: homoscedasticity linear regression\n",
      "Final sentence: simple multiple linear regression\n",
      "Final sentence: general linear models\n",
      "Final sentence: generalized least squares linear regression\n",
      "Final sentence: hierarchical linear models\n",
      "Final sentence: least-squares estimation\n",
      "Final sentence: hey\n",
      "Final sentence: hi\n",
      "Final sentence: \n",
      "Final sentence: going\n",
      "Final sentence: help\n",
      "Final sentence: need help\n",
      "Final sentence: need help\n",
      "Final sentence: hi\n",
      "Final sentence: hello\n",
      "Final sentence: hi chatbot\n",
      "Final sentence: hi great learning\n",
      "Final sentence: hi greatlearning\n",
      "Final sentence: anybody\n",
      "Final sentence: chatbot\n",
      "Final sentence: human\n",
      "Final sentence: greetings\n",
      "Final sentence: nice meet\n",
      "Final sentence: \n",
      "Final sentence: good morning\n",
      "Final sentence: good afternoon\n",
      "Final sentence: good evening\n",
      "Final sentence: good night\n",
      "Final sentence: real\n",
      "Final sentence: machine\n",
      "Final sentence: tell something\n",
      "Final sentence: \n",
      "Final sentence: help\n",
      "Final sentence: question\n",
      "Final sentence: help\n",
      "Final sentence: name\n",
      "Final sentence: knn\n",
      "Final sentence: nearest neighbors algorithm\n",
      "Final sentence: knn\n",
      "Final sentence: k mean knn\n",
      "Final sentence: knn used\n",
      "Final sentence: knn algorithm work\n",
      "Final sentence: knn calculated\n",
      "Final sentence: predict using knn\n",
      "Final sentence: applications knn\n",
      "Final sentence: knn require training\n",
      "Final sentence: knn used regression\n",
      "Final sentence: stop overfitting knn\n",
      "Final sentence: tune knn\n",
      "Final sentence: knn work regression\n",
      "Final sentence: select value k knn\n",
      "Final sentence: knn called lazy learner\n",
      "Final sentence: knn algorithm implemented\n",
      "Final sentence: knn algorithm example\n",
      "Final sentence: knn python\n",
      "Final sentence: knn clustering\n",
      "Final sentence: euclidian distance used knn\n",
      "Final sentence: knn better logistic regression\n",
      "Final sentence: knn non parametric\n",
      "Final sentence: k nearest neighbors algorithm\n",
      "Final sentence: k nearest neighbors\n",
      "Final sentence: k nearest neighbor\n",
      "Final sentence: knn sklearn\n",
      "Final sentence: knn wiki\n",
      "Final sentence: knn example\n",
      "Final sentence: knn python\n",
      "Final sentence: knn algorithm tutorial\n",
      "Final sentence: knn clustering\n",
      "Final sentence: knn supervised unsupervised\n",
      "Final sentence: knn classification\n",
      "Final sentence: knn algorithm data mining\n",
      "Final sentence: knn works\n",
      "Final sentence: unable understand concept knn\n",
      "Final sentence: unable understand concept knn\n",
      "Final sentence: unable understand nearest neighbors\n",
      "Final sentence: unable understand k nearest neighbors\n",
      "Final sentence: unable understand k nearest neighbors\n",
      "Final sentence: unable understand nearest neighbors\n",
      "Final sentence: python library used\n",
      "Final sentence: library python\n",
      "Final sentence: standard libraries python\n",
      "Final sentence: get list python libraries\n",
      "Final sentence: python libraries free\n",
      "Final sentence: python libraries stored\n",
      "Final sentence: python libraries learn\n",
      "Final sentence: many libraries python\n",
      "Final sentence: jason standard python library\n",
      "Final sentence: pandas python\n",
      "Final sentence: python libraries data science\n",
      "Final sentence: python libraries machine\n",
      "Final sentence: python libraries download\n",
      "Final sentence: python modules\n",
      "Final sentence: python package list\n",
      "Final sentence: python modules list\n",
      "Final sentence: python libraries\n",
      "Final sentence: sklearn\n",
      "Final sentence: sklearn libraries\n",
      "Final sentence: scikit learn library\n",
      "Final sentence: scikit learn library\n",
      "Final sentence: sklearn libraries used\n",
      "Final sentence: scikitlearn library\n",
      "Final sentence: scikitlearn library\n",
      "Final sentence: libraries scikit\n",
      "Final sentence: find sklearn libraries\n",
      "Final sentence: library\n",
      "Final sentence: ml libraries\n",
      "Final sentence: library used ml experiments\n",
      "Final sentence: best library machine learning\n",
      "Final sentence: python library\n",
      "Final sentence: python libraries learn\n",
      "Final sentence: python library explain example\n",
      "Final sentence: sklearn library python\n",
      "Final sentence: sklearn stand\n",
      "Final sentence: sklearn scikit learn\n",
      "Final sentence: use sklearn\n",
      "Final sentence: types neural networks\n",
      "Final sentence: neural networks tutorial\n",
      "Final sentence: neural networks\n",
      "Final sentence: neural networks journal\n",
      "Final sentence: neural networks applications\n",
      "Final sentence: neural networks deep learning\n",
      "Final sentence: artificial neural networks\n",
      "Final sentence: neural networks used\n",
      "Final sentence: neural networks work\n",
      "Final sentence: types neural networks\n",
      "Final sentence: neural network artificial intelligence\n",
      "Final sentence: neural networks powerful\n",
      "Final sentence: problems neural networks solve\n",
      "Final sentence: networks powerful\n",
      "Final sentence: neural networks important\n",
      "Final sentence: invented neural network\n",
      "Final sentence: use deep neural networks\n",
      "Final sentence: neural networks deep learning\n",
      "Final sentence: start learning neural networks\n",
      "Final sentence: learn neural networks\n",
      "Final sentence: neural network simple words\n",
      "Final sentence: invented neural networks\n",
      "Final sentence: neural network used deep learning\n",
      "Final sentence: learn neural network\n",
      "Final sentence: understand neural network\n",
      "Final sentence: understand neural network\n",
      "Final sentence: neural network\n",
      "Final sentence: scope neural networks\n",
      "Final sentence: make mathematical model neural network\n",
      "Final sentence: normal computer different neural network\n",
      "Final sentence: neural network used classification\n",
      "Final sentence: data error neural networks\n",
      "Final sentence: recurrent neural networks\n",
      "Final sentence: prepare data neural networks\n",
      "Final sentence: make neural networks\n",
      "Final sentence: learn neural networks\n",
      "Final sentence: train neural networks\n",
      "Final sentence: build neural networks\n",
      "Final sentence: neural network network circuit neurons\n",
      "Final sentence: composed artificial neurons nodes\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Final sentence: biological neural network composed groups chemically connected functional associated neuron\n",
      "Final sentence: neural networks information processing paradigms inspired way biological neural systems process data\n",
      "Final sentence: artificial intelligence cognitive modeling try simulate properties biological neural networks\n",
      "Final sentence: artificial neural networks applied successfully speech recognition image analysis adaptive control\n",
      "Final sentence: origin neural networks based efforts model information processing biological systems\n",
      "Final sentence: neural network computing separate memory processing\n",
      "Final sentence: mcculloch pitts created computational model neural networks based mathematics algorithms\n",
      "Final sentence: called model threshold logic\n",
      "Final sentence: feature selection\n",
      "Final sentence: wrapper method feature selection\n",
      "Final sentence: feature selection ml\n",
      "Final sentence: select best features regression\n",
      "Final sentence: meant feature selection\n",
      "Final sentence: feature selection linear regression\n",
      "Final sentence: feature selection data mining\n",
      "Final sentence: univariate feature selection\n",
      "Final sentence: use feature selection classification\n",
      "Final sentence: decision tree used feature selection\n",
      "Final sentence: correlation based feature selection\n",
      "Final sentence: feature selection feature extraction\n",
      "Final sentence: feature importance calculated\n",
      "Final sentence: permutation feature importance\n",
      "Final sentence: sequential forward selection\n",
      "Final sentence: filter method feature selection\n",
      "Final sentence: filter method feature selection\n",
      "Final sentence: feature selection techniques\n",
      "Final sentence: feature selection regression\n",
      "Final sentence: feature selection logistic regression\n",
      "Final sentence: feature selection using random forest\n",
      "Final sentence: feature selection sklearn\n",
      "Final sentence: feature selection algorithm\n",
      "Final sentence: feature selection methods\n",
      "Final sentence: pca feature selection\n",
      "Final sentence: feature matrix\n",
      "Final sentence: best feature selection method\n",
      "Final sentence: feature selection necessary\n",
      "Final sentence: apply feature selection\n",
      "Final sentence: lasso feature selection\n",
      "Final sentence: random forest need feature selection\n",
      "Final sentence: feature selection data mining\n",
      "Final sentence: type regularization help feature selection\n",
      "Final sentence: f score feature importance\n",
      "Final sentence: boost calculate feature importance\n",
      "Final sentence: permutation feature importance\n",
      "Final sentence: choose feature selection method\n",
      "Final sentence: sequential feature selection classification\n",
      "Final sentence: random forest work\n",
      "Final sentence: random forest supervised unsupervised\n",
      "Final sentence: difference decision tree random forest\n",
      "Final sentence: random forest regression\n",
      "Final sentence: random forest used classification\n",
      "Final sentence: stop overfitting random forest\n",
      "Final sentence: random forest used\n",
      "Final sentence: random forest linear nonlinear\n",
      "Final sentence: use random forest python\n",
      "Final sentence: need normalize data random forest\n",
      "Final sentence: tune random forest python\n",
      "Final sentence: random random forest\n",
      "Final sentence: random forest regression\n",
      "Final sentence: describe random forest\n",
      "Final sentence: random forest deep learning\n",
      "Final sentence: random forest random\n",
      "Final sentence: random forest good\n",
      "Final sentence: random forest used\n",
      "Final sentence: random forest better svm\n",
      "Final sentence: boost better random forest\n",
      "Final sentence: random forest good\n",
      "Final sentence: random forest handle overfitting\n",
      "Final sentence: random forest parametric\n",
      "Final sentence: random forest better decision tree\n",
      "Final sentence: random forest black box model\n",
      "Final sentence: random forest linear classifier\n",
      "Final sentence: difference gradient boosting random forest\n",
      "Final sentence: max features random forest\n",
      "Final sentence: assumptions random forest model\n",
      "Final sentence: random forest algorithm\n",
      "Final sentence: node random forest\n",
      "Final sentence: random forest linear nonlinear\n",
      "Final sentence: limitations random forest regression\n",
      "Final sentence: random forest linear nonlinear\n",
      "Final sentence: improve random forest accuracy\n",
      "Final sentence: random forest linear nonlinear\n",
      "Final sentence: explain random forest\n",
      "Final sentence: random forest model\n",
      "Final sentence: set parameters random forest\n",
      "Final sentence: random forest regression r\n",
      "Final sentence: random forest need feature selection\n",
      "Final sentence: speed random forest\n",
      "Final sentence: random forest reduce bias\n",
      "Final sentence: speed random forest\n",
      "Final sentence: random forest calculate probability\n",
      "Final sentence: many trees random forest\n",
      "Final sentence: random forest need cross validation\n",
      "Final sentence: try random forest\n",
      "Final sentence: oob error calculated random forest\n",
      "Final sentence: random forest need one hot encoding\n",
      "Final sentence: check variable importance random forest\n",
      "Final sentence: tree depth random forest\n",
      "Final sentence: decision tree\n",
      "Final sentence: decision tree tutorial\n",
      "Final sentence: decision tree sklearn\n",
      "Final sentence: decision tree examples solution\n",
      "Final sentence: decision tree classification\n",
      "Final sentence: decision tree analysis\n",
      "Final sentence: decision tree algorithm\n",
      "Final sentence: decision trees used\n",
      "Final sentence: invented decision trees\n",
      "Final sentence: many nodes decision tree\n",
      "Final sentence: decision tree importance\n",
      "Final sentence: disadvantages decision tree\n",
      "Final sentence: decision trees trained\n",
      "Final sentence: decision tree given probability\n",
      "Final sentence: difference decision tree random forest\n",
      "Final sentence: pure node decision tree\n",
      "Final sentence: types decision tree\n",
      "Final sentence: mean decision trees\n",
      "Final sentence: different types decision trees\n",
      "Final sentence: final objective decision tree\n",
      "Final sentence: decision tree supervised learning\n",
      "Final sentence: choose depth decision tree\n",
      "Final sentence: find probability decision tree\n",
      "Final sentence: decision tree data mining\n",
      "Final sentence: decision table example\n",
      "Final sentence: overfitting decision tree\n",
      "Final sentence: analyze decision tree\n",
      "Final sentence: node maximum entropy decision tree\n",
      "Final sentence: avoid overfitting decision tree\n",
      "Final sentence: simplify decision table\n",
      "Final sentence: decision trees use entropy\n",
      "Final sentence: multicollinearity affect decision tree\n",
      "Final sentence: decision tree tutorial\n",
      "Final sentence: use decision tree\n",
      "Final sentence: create decision tree\n",
      "Final sentence: gini index\n",
      "Final sentence: decision tree algorithm work\n",
      "Final sentence: decision tree classifier building scikitlearn\n",
      "Final sentence: decision tree python code example\n",
      "Final sentence: code decision tree\n",
      "Final sentence: decision tree model\n",
      "Final sentence: variable selection\n",
      "Final sentence: select right variables\n",
      "Final sentence: types classification\n",
      "Final sentence: classification models python\n",
      "Final sentence: classification algorithms\n",
      "Final sentence: classification algorithms data mining\n",
      "Final sentence: classification models\n",
      "Final sentence: classification data science\n",
      "Final sentence: mention classification models\n",
      "Final sentence: name supervised learning algorithms\n",
      "Final sentence: types supervised learning models\n",
      "Final sentence: supervised learning python\n",
      "Final sentence: supervised learning algorithms\n",
      "Final sentence: supervised learning algorithms data mining\n",
      "Final sentence: supervised learning methods\n",
      "Final sentence: supervised learning data science\n",
      "Final sentence: mention supervised learning topics\n",
      "Final sentence: name unsupervised learning algorithms\n",
      "Final sentence: types unsupervised learning models\n",
      "Final sentence: unsupervised learning python\n",
      "Final sentence: unsupervised learning\n",
      "Final sentence: unsupervised learning algorithms\n",
      "Final sentence: unsupervised learning algorithms data mining\n",
      "Final sentence: unsupervised learning methods\n",
      "Final sentence: unsupervised learning data science\n",
      "Final sentence: mention unsupervised learning topics\n",
      "Final sentence: meant k means clustering algorithm\n",
      "Final sentence: calculate k means clustering\n",
      "Final sentence: k means clustering used\n",
      "Final sentence: kind clusters k means clustering algorithm produce\n",
      "Final sentence: k means clustering used\n",
      "Final sentence: k means algorithm example\n",
      "Final sentence: clustering used\n",
      "Final sentence: elbow method k means\n",
      "Final sentence: use elbow method\n",
      "Final sentence: get different results different runs k means clustering\n",
      "Final sentence: k means cluster python\n",
      "Final sentence: explain means clustering\n",
      "Final sentence: means clustering simple explanation\n",
      "Final sentence: data clustering algorithm\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Final sentence: means algorithm work\n",
      "Final sentence: principal component analysis clustering\n",
      "Final sentence: difference pca cluster analysis\n",
      "Final sentence: pca used\n",
      "Final sentence: pca unsupervised technique\n",
      "Final sentence: pca analysis\n",
      "Final sentence: pca cluster\n",
      "Final sentence: pca classifier\n",
      "Final sentence: pca calculated\n",
      "Final sentence: pca method\n",
      "Final sentence: pca improve accuracy\n",
      "Final sentence: pca supervised\n",
      "Final sentence: pca components\n",
      "Final sentence: choose pca component\n",
      "Final sentence: pca clustering\n",
      "Final sentence: pca loading\n",
      "Final sentence: pca used prediction\n",
      "Final sentence: pca reduce features\n",
      "Final sentence: boosting work machine learning\n",
      "Final sentence: bagging boosting\n",
      "Final sentence: adaboost\n",
      "Final sentence: weak learner\n",
      "Final sentence: catboost better boost\n",
      "Final sentence: boosting ml\n",
      "Final sentence: main objective boosting\n",
      "Final sentence: boosting overfit\n",
      "Final sentence: boosting better bagging\n",
      "Final sentence: boost faster rbm\n",
      "Final sentence: boost take categorical features input\n",
      "Final sentence: random forest boosting algorithm\n",
      "Final sentence: boosting reduce variance\n",
      "Final sentence: want use weak learners boosting\n",
      "Final sentence: fix overfitting problems\n",
      "Final sentence: boosting ensemble\n",
      "Final sentence: adaboost\n",
      "Final sentence: boosting use bootstrap\n",
      "Final sentence: catboost algorithm\n",
      "Final sentence: bagging technique\n",
      "Final sentence: bagging classifier\n",
      "Final sentence: purpose bagging\n",
      "Final sentence: bootstrapping bagging\n",
      "Final sentence: bagging\n",
      "Final sentence: bagging technique ml\n",
      "Final sentence: bagging reduce overfitting\n",
      "Final sentence: boosting better bagging\n",
      "Final sentence: random forest bagging boosting\n",
      "Final sentence: bagging decision tree\n",
      "Final sentence: full form term bagging\n",
      "Final sentence: bagging overfit\n",
      "Final sentence: bagging decrease variance\n",
      "Final sentence: difference bagging random forest\n",
      "Final sentence: bootstrap aggregation\n",
      "Final sentence: bagging technique uses row column sampling ensemble\n",
      "Final sentence: statistical inference\n",
      "Final sentence: inferential statistics used\n",
      "Final sentence: difference descriptive inferential statistics\n",
      "Final sentence: inferential statistical tests\n",
      "Final sentence: examples inferential statistics\n",
      "Final sentence: inferential statistics quantitative quantitative\n",
      "Final sentence: chi square inferential\n",
      "Final sentence: write inferential statistics\n",
      "Final sentence: know inferential test use\n",
      "Final sentence: test inferential descriptive statistics\n",
      "Final sentence: main type inferential statistics\n",
      "Final sentence: comes inferential statistics\n",
      "Final sentence: anova inferential statistics\n",
      "Final sentence: advantages inferential statistics\n",
      "Final sentence: two types inferential statistics\n",
      "Final sentence: research method fits inferential statistics\n",
      "Final sentence: use descriptive inferential statistics\n",
      "Final sentence: explain eda\n",
      "Final sentence: exploratory data analysis\n",
      "Final sentence: eda necessary\n",
      "Final sentence: exploratory data analysis example\n",
      "Final sentence: exploratory data analysis python\n",
      "Final sentence: exploratory data analysis python course\n",
      "Final sentence: python exploratory data analysis package\n",
      "Final sentence: exploratory data analysis python github\n",
      "Final sentence: eda stand data science\n",
      "Final sentence: eda\n",
      "Final sentence: importance eda\n",
      "Final sentence: exploratory data analysis importance\n",
      "Final sentence: eda important\n",
      "Final sentence: explain descriptive statistics\n",
      "Final sentence: meant descriptive statistics\n",
      "Final sentence: examples descriptive statistics\n",
      "Final sentence: types descriptive statistics\n",
      "Final sentence: want know descriptive statistics\n",
      "Final sentence: descriptive statistics important\n",
      "Final sentence: descriptive statistics approach\n",
      "Final sentence: interpret descriptive statistics excel\n",
      "Final sentence: importance descriptive statistics\n",
      "Final sentence: descriptive statistics pdf\n",
      "Final sentence: different approached descriptive statistics\n",
      "Final sentence: give introduction descriptive statistics\n",
      "Final sentence: logistic regression\n",
      "Final sentence: logistic regression popular\n",
      "Final sentence: types logistic regression\n",
      "Final sentence: logistic regression better linear\n",
      "Final sentence: logistic regression work\n",
      "Final sentence: logistic regression non linear\n",
      "Final sentence: assumptions using logistic regression\n",
      "Final sentence: logistic regression gym\n",
      "Final sentence: logistic regression better\n",
      "Final sentence: logistic regression linear\n",
      "Final sentence: use logistic regression\n",
      "Final sentence: logistic regression tutorial\n",
      "Final sentence: machine learning visualization python\n",
      "Final sentence: want know data visualization techniques\n",
      "Final sentence: visualization techniques data mining\n",
      "Final sentence: best visualization techniques\n",
      "Final sentence: want understand data visualization\n",
      "Final sentence: become expert data visualization\n",
      "Final sentence: improve visualization skills\n",
      "Final sentence: visualization important\n",
      "Final sentence: univariate visualizations\n",
      "Final sentence: different type data visualization tools\n",
      "Final sentence: different type bi-variate visualization graphs\n",
      "Final sentence: become better data visualization\n",
      "Final sentence: anova test\n",
      "Final sentence: assumptions anova\n",
      "Final sentence: use anova\n",
      "Final sentence: use anova instead test\n",
      "Final sentence: output anova test\n",
      "Final sentence: difference one way anova two way anova\n",
      "Final sentence: interpret anova results\n",
      "Final sentence: full form anova\n",
      "Final sentence: anova test tell\n",
      "Final sentence: explain anova example\n",
      "Final sentence: one-way anova test approach\n",
      "Final sentence: understand use anova test use test\n",
      "Final sentence: deep learning examples\n",
      "Final sentence: deep learning used\n",
      "Final sentence: deep learning vs machine learning\n",
      "Final sentence: called deep learning\n",
      "Final sentence: please explain deep learning\n",
      "Final sentence: deep learning\n",
      "Final sentence: computer vision\n",
      "Final sentence: computer vision example\n",
      "Final sentence: image processing computer vision\n",
      "Final sentence: machine learning\n",
      "Final sentence: please explain machine learning\n",
      "Final sentence: types machine learning\n",
      "Final sentence: machine learning done\n",
      "Final sentence: ml\n",
      "Final sentence: explain ml\n",
      "Final sentence: ml performed\n",
      "Final sentence: library primarily used machine learning\n",
      "Final sentence: best machine learning library\n",
      "Final sentence: ml library\n",
      "Final sentence: library primarily used machine learning\n",
      "Final sentence: classic ml algorithms\n",
      "Final sentence: machine learning curriculum\n",
      "Final sentence: machine learning data science\n",
      "Final sentence: mention machine learning topics\n",
      "Final sentence: computer vision problems\n",
      "Final sentence: library use build machine learning models\n",
      "Final sentence: choose features machine learning\n",
      "Final sentence: knn machine learning\n",
      "Final sentence: python library used machine learning\n",
      "Final sentence: python libraries machine learning\n",
      "Final sentence: machine learning library\n",
      "Final sentence: neural networks machine learning\n",
      "Final sentence: neural network machine learning\n",
      "Final sentence: choose feature selection method machine learning\n",
      "Final sentence: random forest algorithm machine learning\n",
      "Final sentence: decision tree machine learning\n",
      "Final sentence: classification machine learning\n",
      "Final sentence: supervised learning machine learning\n",
      "Final sentence: unsupervised learning machine learning\n",
      "Final sentence: name topics machine learning\n",
      "Final sentence: machine learning techniques\n",
      "Final sentence: machine learning python\n",
      "Final sentence: ai\n",
      "Final sentence: fundamentals ai\n",
      "Final sentence: fundamentals ml\n",
      "Final sentence: different techniques ai\n",
      "Final sentence: curriculum ml\n",
      "Final sentence: machine learning algorithms data mining\n",
      "Final sentence: machine learning methods\n",
      "Final sentence: bagging boosting machine learning\n",
      "Final sentence: bagging machine learning\n",
      "Final sentence: bias machine learning\n",
      "Final sentence: bagging technique uses row column sampling ensemble machine learning\n",
      "Final sentence: eda necessary machine learning\n",
      "Final sentence: best visualization techniques machine learning\n",
      "Final sentence: computer vision machine learning\n",
      "Final sentence: artificial intelligence\n",
      "Final sentence: fundamentals artificial intelligence\n",
      "Final sentence: different techniques artificial intelligence\n",
      "Final sentence: explain artificial intelligence\n"
     ]
    }
   ],
   "source": [
    "df['transformed_query'] = df['query'].apply(cleanText)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Preparing list of queries to compare to later to store new queries\n",
    "query_list = df['query'].tolist()\n",
    "query_list = [i.lower() for i in query_list]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# encoding the target column\n",
    "le = LabelEncoder()\n",
    "df['tag_encoded'] = le.fit_transform(df['tag'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Converting with bag of words\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "cv = CountVectorizer(ngram_range=(1, 2))\n",
    "X = cv.fit_transform(df['transformed_query']).toarray()\n",
    "\n",
    "y = df['tag_encoded']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Creating dataframe to visualize data\n",
    "temp_name = cv.get_feature_names()\n",
    "temp = pd.DataFrame(X, columns=temp_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create dictionary for tag to response\n",
    "temp = df[['tag_encoded', 'response']]\n",
    "temp = temp.groupby(['tag_encoded']).max()\n",
    "resp_dict = temp.to_dict()\n",
    "resp_dict = resp_dict['response']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Test code"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_file = pd.read_csv('test_set.csv')\n",
    "#test_file = pd.read_csv('gl_test_data.csv')\n",
    "test_file.columns = ['query', 'tag']\n",
    "Xt1 = cv.transform(test_file['query']).toarray()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# le1 = le.fit(df['tag'])\n",
    "# df['tag_encoded'] = le1.transform(df['tag'])\n",
    "\n",
    "yt1 = le.transform(test_file['tag'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# for testing accuracy of the test set\n",
    "import xgboost as xgb\n",
    "from xgboost import XGBClassifier\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "\n",
    "model_xg = XGBClassifier(seed = 10)\n",
    "model_xg = model_xg.fit(X, y)\n",
    "y_pred_xg = model_xg.predict(Xt1)\n",
    "\n",
    "print(\"Test File Accuracy\",metrics.accuracy_score(yt1, y_pred_xg))\n",
    "\n",
    "with open(\"bot_model.pickle\",'wb') as f:\n",
    "    pickle.dump(model_xg,f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Test code ends here"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Fitting naive bayes algorithm\n",
    "# mnb = MultinomialNB()\n",
    "# model = mnb.fit(X, y)\n",
    "\n",
    "# y_pred = model.predict(X)\n",
    "# print(\"Validation Accuracy:\",metrics.accuracy_score(y, y_pred))\n",
    "\n",
    "# with open(\"bot_model.pickle\",'wb') as f:\n",
    "#     pickle.dump(model,f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Xgboost predictor\n",
    "import xgboost as xgb\n",
    "from xgboost import XGBClassifier\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "\n",
    "model_xg = XGBClassifier(seed = 10)\n",
    "model_xg = model_xg.fit(X, y)\n",
    "y_pred = model_xg.predict(X)\n",
    "\n",
    "print(\"Validation Accuracy:\",metrics.accuracy_score(y, y_pred))\n",
    "\n",
    "with open(\"bot_model.pickle\",'wb') as f:\n",
    "    pickle.dump(model_xg,f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Random forest classifier\n",
    "\n",
    "# model_rf = RandomForestClassifier()\n",
    "# model_rf = model_rf.fit(X, y)\n",
    "# y_pred = model_rf.predict(X)\n",
    "# print(\"Validation Accuracy:\",metrics.accuracy_score(y, y_pred))\n",
    "\n",
    "# with open(\"bot_model.pickle\",'wb') as f:\n",
    "#     pickle.dump(model_xg,f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Model building ends here"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Test code starts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Predict using model\n",
    "def process_input(s1):\n",
    "#    s1 = 'What is linear regression?'\n",
    "    s1 = cleanText(s1)\n",
    "    l1=[]\n",
    "    l1.append(s1)\n",
    "    ldf = pd.DataFrame(l1, columns= ['query'])\n",
    "    return ldf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Test code to be removed\n",
    "ss = 'what is EDA'\n",
    "query_df = process_input(ss)\n",
    "X_test     = cv.transform(query_df['query']).toarray()\n",
    "prediction = model_xg.predict(X_test)\n",
    "prediction_proba = model_xg.predict_proba(X_test)\n",
    "print(prediction)\n",
    "print(prediction_proba.max())\n",
    "print(prediction_proba)\n",
    "print(model_xg.classes_)\n",
    "resp       = getResponse(prediction[0])\n",
    "print(resp)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from matplotlib import pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.bar(model_xg.classes_, prediction_proba[0])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Testing code end here"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Start of prediction flow"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Using pickle"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Trying pickle with model\n",
    "pickle_in = open('./bot_model.pickle','rb')\n",
    "classifier = pickle.load(pickle_in)\n",
    "pickle_in.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Original code to run for bot"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Landing message\n",
    "print(Fore.RED +  \"Hello. I am your machine learning assistant\")\n",
    "print(\"I can help you with your learning journey.\")\n",
    "print(Fore.CYAN + \"You can ask me questions around algorithms and learn new stuff!!\")\n",
    "print(Style.RESET_ALL)\n",
    "time.sleep(4)\n",
    "\n",
    "# Get input from user\n",
    "inp_text=''\n",
    "confirmation= ''\n",
    "i = 0\n",
    "context = 'predict'\n",
    "\n",
    "while(context != 'quit'):\n",
    "    print(Style.RESET_ALL)\n",
    "    context = 'predict'\n",
    "    inp_text = input('User: ')\n",
    "    print(Fore.BLUE)    \n",
    "### Sanjay\n",
    "#    print(\"Cleaned text:\", clean_greeting(inp_text))  ## debug\n",
    "    if (clean_greeting(inp_text) in quit_words):\n",
    "        context = 'quit'\n",
    "#    print(\"After checking quit words\", inp_text)  ##debug\n",
    "\n",
    "### Sanjay\n",
    "    if (clean_greeting(inp_text) in greetings):\n",
    "#         print(\"Setting context to greeting\")  ##debug\n",
    "        context = 'greeting'\n",
    "    \n",
    "#     print(\"After checking greeting words:\", inp_text, \", context:\", context)  ##debug\n",
    "\n",
    "    if(context != 'quit'):\n",
    "        if(context != 'greeting'):\n",
    "            if(inp_text.lower() not in query_list):\n",
    "                store_new_query(inp_text)\n",
    "            query_df   = process_input(inp_text)\n",
    "#            print(\"Input for model:\", query_df)    ##debug\n",
    "            X_test     = cv.transform(query_df['query']).toarray()\n",
    "            prediction = classifier.predict(X_test)\n",
    "            max_probab = classifier.predict_proba(X_test).max()\n",
    "            print(\"predicted value {} with probability {}\".format(prediction, max_probab))   ##debug\n",
    "            if (max_probab > .60):\n",
    "                resp       = getResponse(prediction[0])\n",
    "                process_response(resp)\n",
    "            else:\n",
    "                print_fallback_message(i)\n",
    "                i = i + 1\n",
    "        else:\n",
    "            if(inp_text.lower() in ['ok','cool']):\n",
    "                print(\"I am glad to assist you. You can ask me other questions.\")\n",
    "            else:\n",
    "                print(\"Hello! how can I help you ?\")\n",
    "    else:\n",
    "        print(\"Do you want to quit? (yes/no)\")\n",
    "        print(Style.RESET_ALL)\n",
    "        confirmation = input('User: ')\n",
    "#        print(\"confirm text:\",confirmation,\",\",confirmation.lower())   ##debug\n",
    "        print(Fore.BLUE)\n",
    "        if confirmation.lower() == 'yes':\n",
    "            context = 'quit'\n",
    "            print(\"Thanks. See you again\")\n",
    "        elif confirmation.lower() == 'no':\n",
    "#            print(\"Inside else\")   ##debug\n",
    "            context = 'predict'\n",
    "        else:\n",
    "            print(\"Valid response is yes/no.\")\n",
    "            print(\"You can ask me other questions. :)\")\n",
    "            context = 'predict'\n",
    "#        print(\"End of loop context:\", context)    ##debug\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for a in resp_dict:\n",
    "    print(a,resp_dict[a])\n",
    "\n",
    "\n",
    "#print(resp_dict)  ##debug"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
