{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "import nltk\n",
    "from nltk.stem import PorterStemmer\n",
    "import re\n",
    "import pickle\n",
    "import time\n",
    "from colorama import Fore, Back, Style\n",
    "\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from sklearn.naive_bayes import MultinomialNB\n",
    "from sklearn import metrics\n",
    "\n",
    "\n",
    "import urllib.request\n",
    "import webbrowser"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "from nltk.corpus import stopwords\n",
    "quit_words = ['quit', 'bye', 'thanks', 'exit', 'thankyou', 'thank you', 'thanku']\n",
    "\n",
    "greetings = [\"hello\",\"hey\",\"hi\",\"hello\",\"how are you?\",\"how's it going\",\"help\",\"i need some help\",\"i need help\",\"hi there\",\n",
    "\"hello there\",\"hi chatbot\",\"hi great learning\",\"hi greatlearning\",\"anybody there?\",\"are you a chatbot?\",\n",
    "\"are you human?\",\"greetings!\",\"nice to meet you\",\"what's up?\",\"good morning\",\"good afternoon\",\"good evening\",\n",
    "\"good night\",\"are you real?\",\"you're a machine?\",\"tell me something\",\"what can you do?\",\"how can you help me\",\n",
    "\"i have a question\",\"can you help me\",\"what's your name\",\"greetings\",\"morning\",\"afternoon\",\"hello chatbot\",\"check\",\"test\",\"howdy\",\n",
    "\"morning\",\"afternoon\",\"evening\"]\n",
    "\n",
    "# root to be used as random state\n",
    "root = 42"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Common functions definition\n",
    "\n",
    "def cleanText(s1):\n",
    "    ps = PorterStemmer()\n",
    "    text = s1.lower()\n",
    "    text = re.sub(r'[0-9]*','',text)\n",
    "    text = re.sub(r'^([a-z],[A-Z])*','',text)\n",
    "    text = re.sub(r'\\s\\s+',' ',text)\n",
    "    text = [ps.stem(word) for word in nltk.word_tokenize(text) if word not in stopwords.words('english')]\n",
    "    text = ' '.join(text)\n",
    "    return text\n",
    "\n",
    "# After prediction convert tag to response\n",
    "def getResponse(tag):\n",
    "    try:\n",
    "        if(resp_dict[tag]):\n",
    "            response = resp_dict[tag]\n",
    "            return response\n",
    "        else:\n",
    "            print('Response not found.. Please try another query.')\n",
    "    except:\n",
    "        print('Response not found for:', tag)\n",
    "        print('I will update my knowledge soon :)')\n",
    "\n",
    "def process_response(response):\n",
    "    if(response[0:4]=='Link'):\n",
    "        url = response[5:]\n",
    "#        webbrowser.open(url)\n",
    "        print(\"Bot: url to open is {}\".format(url))\n",
    "    else:\n",
    "        print(\"Bot: \", response)\n",
    "\n",
    "def store_new_query(query):\n",
    "    with open(\"non_corpus_queries.txt\", \"a\") as f:\n",
    "        f.write(inp_text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv(\"Corpus_1.csv\")\n",
    "df.columns = ['query', 'response', 'tag']\n",
    "df = df.dropna()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>query</th>\n",
       "      <th>response</th>\n",
       "      <th>tag</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>0</td>\n",
       "      <td>Hello</td>\n",
       "      <td>Hello! how can I help you ?</td>\n",
       "      <td>hello</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>Linear Regression formula</td>\n",
       "      <td>Link:https://en.wikipedia.org/wiki/Linear_regr...</td>\n",
       "      <td>Linear regression</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                       query  \\\n",
       "0                      Hello   \n",
       "1  Linear Regression formula   \n",
       "\n",
       "                                            response                tag  \n",
       "0                        Hello! how can I help you ?              hello  \n",
       "1  Link:https://en.wikipedia.org/wiki/Linear_regr...  Linear regression  "
      ]
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['transformed_query'] = df['query'].apply(cleanText)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Preparing list of queries to compare to later to store new queries\n",
    "query_list = df['query'].tolist()\n",
    "query_list = [i.lower() for i in query_list]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [],
   "source": [
    "# encoding the target column\n",
    "le = LabelEncoder()\n",
    "df['tag_encoded'] = le.fit_transform(df['tag'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Converting with bag of words\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "cv = CountVectorizer(ngram_range=(1, 2))\n",
    "X = cv.fit_transform(df['transformed_query']).toarray()\n",
    "\n",
    "y = df['tag_encoded']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Creating dataframe to visualize data\n",
    "temp_name = cv.get_feature_names()\n",
    "temp = pd.DataFrame(X, columns=temp_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create dictionary for tag to response\n",
    "temp = df[['tag_encoded', 'response']]\n",
    "temp = temp.groupby(['tag_encoded']).max()\n",
    "resp_dict = temp.to_dict()\n",
    "resp_dict = resp_dict['response']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Test code"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Test code to check accuracy\n",
    "# from sklearn.model_selection import train_test_split\n",
    "# X_train, X_test, y_train, y_test = train_test_split(X, y, test_size = 0.3, random_state = root)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [],
   "source": [
    "# from sklearn.naive_bayes import MultinomialNB\n",
    "# from sklearn.ensemble import RandomForestClassifier\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [],
   "source": [
    "#mnb = MultinomialNB()\n",
    "#model = mnb.fit(X_train, y_train)\n",
    "\n",
    "# rf = RandomForestClassifier()\n",
    "# model = rf.fit(X_train,y_train)\n",
    "\n",
    "# from xgboost import XGBClassifier\n",
    "# xgb = XGBClassifier()\n",
    "# model = xgb.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [],
   "source": [
    "# y_pred = model.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [],
   "source": [
    "# from sklearn.metrics import accuracy_score\n",
    "# score = accuracy_score(y_test, y_pred)\n",
    "# print(score)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Test code ends here"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation Accuracy: 1.0\n"
     ]
    }
   ],
   "source": [
    "# Fitting naive bayes algorithm\n",
    "mnb = MultinomialNB()\n",
    "model = mnb.fit(X, y)\n",
    "\n",
    "# Mohit - we are taking accuracy on data on which we have trained model\n",
    "print(\"Validation Accuracy:\",metrics.accuracy_score(y, y_pred))\n",
    "\n",
    "with open(\"bot_model.pickle\",'wb') as f:\n",
    "    pickle.dump(model,f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation Accuracy: 0.9704797047970479\n"
     ]
    }
   ],
   "source": [
    "# Xgboost predictor\n",
    "import xgboost as xgb\n",
    "from xgboost import XGBClassifier\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "\n",
    "model_xg = XGBClassifier()\n",
    "model_xg = model_xg.fit(X, y)\n",
    "y_pred = model_xg.predict(X)\n",
    "\n",
    "print(\"Validation Accuracy:\",metrics.accuracy_score(y, y_pred))\n",
    "\n",
    "with open(\"bot_model.pickle\",'wb') as f:\n",
    "    pickle.dump(model_xg,f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation Accuracy: 0.992619926199262\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\ensemble\\forest.py:245: FutureWarning: The default value of n_estimators will change from 10 in version 0.20 to 100 in 0.22.\n",
      "  \"10 in version 0.20 to 100 in 0.22.\", FutureWarning)\n"
     ]
    }
   ],
   "source": [
    "# Random forest classifier\n",
    "\n",
    "model_rf = RandomForestClassifier()\n",
    "model_rf = model_rf.fit(X, y)\n",
    "y_pred = model_rf.predict(X)\n",
    "print(\"Validation Accuracy:\",metrics.accuracy_score(y, y_pred))\n",
    "\n",
    "with open(\"bot_model.pickle\",'wb') as f:\n",
    "    pickle.dump(model_xg,f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Model building ends here"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[8]\n",
      "0.21402214022140223\n",
      "Link:https://en.wikipedia.org/wiki/Neural_network\n",
      "Bot: url to open is https://en.wikipedia.org/wiki/Neural_network\n"
     ]
    }
   ],
   "source": [
    "# Test code to be removed\n",
    "# Prabu - added predict proba\n",
    "ss = 'how are you'\n",
    "query_df = process_input(ss)\n",
    "X_test     = cv.transform(query_df['query']).toarray()\n",
    "prediction = model.predict(X_test)\n",
    "prediction_proba = model.predict_proba(X_test)\n",
    "print(prediction)\n",
    "print(prediction_proba.max())\n",
    "resp       = getResponse(prediction[0])\n",
    "print(resp)\n",
    "process_response(resp)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Predict using model\n",
    "def process_input(s1):\n",
    "#    s1 = 'What is linear regression?'\n",
    "    s1 = cleanText(s1)\n",
    "    l1=[]\n",
    "    l1.append(s1)\n",
    "    ldf = pd.DataFrame(l1, columns= ['query'])\n",
    "    return ldf\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Start of prediction flow"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Using pickle"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Trying pickle with model\n",
    "pickle_in = open('./bot_model.pickle','rb')\n",
    "classifier = pickle.load(pickle_in)\n",
    "pickle_in.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Original code to run for bot"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[31mHello. I am your machine learning assistant\n",
      "I can help you with your learning journey.\n",
      "\u001b[36mYou can ask me questions around algorithms and learn new stuff!!\n",
      "\u001b[0m\n",
      "User: hi\n",
      "Bot:  Hello! how can I help you ?\n",
      "User: can you tell about knn\n",
      "Bot: url to open is https://en.wikipedia.org/wiki/K-nearest_neighbors_algorithm\n",
      "User: and about machine learning\n",
      "Bot: url to open is https://en.wikipedia.org/wiki/Machine_learning\n",
      "User: what is neurl network\n",
      "Bot: url to open is https://en.wikipedia.org/wiki/Neural_network\n",
      "User: oki\n",
      "Bot:  Hello! how can I help you ?\n",
      "User: thanks\n",
      "Thanks. See you again\n"
     ]
    }
   ],
   "source": [
    "# Landing message\n",
    "print(Fore.RED +  \"Hello. I am your machine learning assistant\")\n",
    "print(\"I can help you with your learning journey.\")\n",
    "print(Fore.CYAN + \"You can ask me questions around algorithms and learn new stuff!!\")\n",
    "print(Style.RESET_ALL)\n",
    "time.sleep(4)\n",
    "\n",
    "# Get input from user\n",
    "inp_text=''\n",
    "while(inp_text != 'quit'):\n",
    "    inp_text = input('User: ')\n",
    "    \n",
    "    if (inp_text in quit_words):\n",
    "        inp_text = 'quit'\n",
    "    \n",
    "    if (inp_text in greetings):\n",
    "        inp_text = 'greeting'\n",
    "        \n",
    "    if(inp_text != 'quit'):\n",
    "        if(inp_text != 'greeting'):\n",
    "            if(inp_text.lower() not in query_list):\n",
    "                store_new_query(inp_text)\n",
    "            query_df   = process_input(inp_text)\n",
    "    #         print(query_df)\n",
    "            X_test     = cv.transform(query_df['query']).toarray()\n",
    "            prediction = classifier.predict(X_test)\n",
    "            resp       = getResponse(prediction[0])\n",
    "            process_response(resp)\n",
    "        else:\n",
    "            print(\"Hello! how can I help you ?\")\n",
    "    else:\n",
    "        print(\"Thanks. See you again\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
