{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "import nltk\n",
    "from nltk.stem import PorterStemmer\n",
    "import re\n",
    "import pickle\n",
    "import time\n",
    "from colorama import Fore, Back, Style\n",
    "\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from sklearn.naive_bayes import MultinomialNB\n",
    "from sklearn import metrics\n",
    "\n",
    "\n",
    "import urllib.request\n",
    "import webbrowser"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [],
   "source": [
    "from nltk.corpus import stopwords\n",
    "quit_words = ['quit', 'bye', 'thanks', 'exit', 'thankyou', 'thank you', 'thanku']\n",
    "\n",
    "greetings = [\"hello\",\"hey\",\"hi\",\"hello\",\"how are you?\",\"how's it going\",\"help\",\"i need some help\",\"i need help\",\"hi there\",\n",
    "\"hello there\",\"hi chatbot\",\"hi great learning\",\"hi greatlearning\",\"anybody there?\",\"are you a chatbot?\",\n",
    "\"are you human?\",\"greetings!\",\"nice to meet you\",\"what's up?\",\"good morning\",\"good afternoon\",\"good evening\",\n",
    "\"good night\",\"are you real?\",\"you're a machine?\",\"tell me something\",\"what can you do?\",\"how can you help me\",\n",
    "\"i have a question\",\"can you help me\",\"what's your name\",\"greetings\",\"morning\",\"afternoon\",\"hello chatbot\",\"check\",\"test\",\"howdy\",\n",
    "\"morning\",\"afternoon\",\"evening\"]\n",
    "\n",
    "# root to be used as random state\n",
    "root = 42"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Spelling correction\n",
    "import re\n",
    "from collections import Counter\n",
    "\n",
    "def words(text): return re.findall(r'\\w+', text.lower())\n",
    "\n",
    "WORDS = Counter(words(open('big_ml.txt', encoding=\"utf8\").read()))\n",
    "\n",
    "def P(word, N=sum(WORDS.values())): \n",
    "    \"Probability of `word`.\"\n",
    "    return WORDS[word] / N\n",
    "\n",
    "def correction(word): \n",
    "    \"Most probable spelling correction for word.\"\n",
    "    return max(candidates(word), key=P)\n",
    "\n",
    "def candidates(word): \n",
    "    \"Generate possible spelling corrections for word.\"\n",
    "    return (known([word]) or known(edits1(word)) or known(edits2(word)) or [word])\n",
    "\n",
    "def known(words): \n",
    "    \"The subset of `words` that appear in the dictionary of WORDS.\"\n",
    "    return set(w for w in words if w in WORDS)\n",
    "\n",
    "def edits1(word):\n",
    "    \"All edits that are one edit away from `word`.\"\n",
    "    letters    = 'abcdefghijklmnopqrstuvwxyz'\n",
    "    splits     = [(word[:i], word[i:])    for i in range(len(word) + 1)]\n",
    "    deletes    = [L + R[1:]               for L, R in splits if R]\n",
    "    transposes = [L + R[1] + R[0] + R[2:] for L, R in splits if len(R)>1]\n",
    "    replaces   = [L + c + R[1:]           for L, R in splits if R for c in letters]\n",
    "    inserts    = [L + c + R               for L, R in splits for c in letters]\n",
    "    return set(deletes + transposes + replaces + inserts)\n",
    "\n",
    "def edits2(word): \n",
    "    \"All edits that are two edits away from `word`.\"\n",
    "    return (e2 for e1 in edits1(word) for e2 in edits1(e1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Common functions definition\n",
    "\n",
    "def cleanText(s1):\n",
    "    ps = PorterStemmer()\n",
    "    text = s1.lower()\n",
    "    text = re.sub(r'[0-9]*','',text)\n",
    "    text = re.sub(r'^([a-z],[A-Z])*','',text)\n",
    "    text = re.sub(r'\\s\\s+',' ',text)\n",
    "    word_list = []\n",
    "    for word in nltk.word_tokenize(text):\n",
    "        \n",
    "#        print(\"Original word:\", word)  ## debug print\n",
    "        word = correction(word)\n",
    "#        print(\"corrected word:\", word)  ##debug print\n",
    "        if(word not in stopwords.words('english')):\n",
    "            ps.stem(word)\n",
    "            word_list.append(word)\n",
    "    text = word_list\n",
    "\n",
    "### Removed below line after adding code for spelling correction\n",
    "#    text = [ps.stem(word) for word in nltk.word_tokenize(text) if word not in stopwords.words('english')]\n",
    "    text = ' '.join(text)\n",
    "#    print(\"Final sentence:\", text)  ## debug print\n",
    "    return text\n",
    "\n",
    "# After prediction convert tag to response\n",
    "def getResponse(tag):\n",
    "    try:\n",
    "        if(resp_dict[tag]):\n",
    "            response = resp_dict[tag]\n",
    "            return response\n",
    "        else:\n",
    "            print('Response not found.. Please try another query.')\n",
    "    except:\n",
    "        print('Response not found for:', tag)\n",
    "        print('I will update my knowledge soon :)')\n",
    "\n",
    "def process_response(response):\n",
    "    if(response[0:4]=='Link'):\n",
    "        url = response[5:]\n",
    "#        webbrowser.open(url)\n",
    "        print(\"Bot: url to open is {}\".format(url))\n",
    "    else:\n",
    "        print(\"Bot: \", response)\n",
    "\n",
    "def store_new_query(query):\n",
    "    with open(\"non_corpus_queries.txt\", \"a\") as f:\n",
    "        str = inp_text + \"\\n\"\n",
    "        f.write(str)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'find neural network'"
      ]
     },
     "execution_count": 52,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# test code\n",
    "\n",
    "st = \"find about neaurel networ\"\n",
    "cleanText(st)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv(\"Corpus_1.csv\")\n",
    "df.columns = ['query', 'response', 'tag']\n",
    "df = df.dropna()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>query</th>\n",
       "      <th>response</th>\n",
       "      <th>tag</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>0</td>\n",
       "      <td>Hello</td>\n",
       "      <td>Hello! how can I help you ?</td>\n",
       "      <td>hello</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>Linear Regression formula</td>\n",
       "      <td>Link:https://en.wikipedia.org/wiki/Linear_regr...</td>\n",
       "      <td>Linear regression</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                       query  \\\n",
       "0                      Hello   \n",
       "1  Linear Regression formula   \n",
       "\n",
       "                                            response                tag  \n",
       "0                        Hello! how can I help you ?              hello  \n",
       "1  Link:https://en.wikipedia.org/wiki/Linear_regr...  Linear regression  "
      ]
     },
     "execution_count": 54,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['transformed_query'] = df['query'].apply(cleanText)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Preparing list of queries to compare to later to store new queries\n",
    "query_list = df['query'].tolist()\n",
    "query_list = [i.lower() for i in query_list]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [],
   "source": [
    "# encoding the target column\n",
    "le = LabelEncoder()\n",
    "df['tag_encoded'] = le.fit_transform(df['tag'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Converting with bag of words\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "cv = CountVectorizer(ngram_range=(1, 2))\n",
    "X = cv.fit_transform(df['transformed_query']).toarray()\n",
    "\n",
    "y = df['tag_encoded']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Creating dataframe to visualize data\n",
    "temp_name = cv.get_feature_names()\n",
    "temp = pd.DataFrame(X, columns=temp_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create dictionary for tag to response\n",
    "temp = df[['tag_encoded', 'response']]\n",
    "temp = temp.groupby(['tag_encoded']).max()\n",
    "resp_dict = temp.to_dict()\n",
    "resp_dict = resp_dict['response']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Test code"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Test code to check accuracy\n",
    "# from sklearn.model_selection import train_test_split\n",
    "# X_train, X_test, y_train, y_test = train_test_split(X, y, test_size = 0.3, random_state = root)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [],
   "source": [
    "# from sklearn.naive_bayes import MultinomialNB\n",
    "# from sklearn.ensemble import RandomForestClassifier\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [],
   "source": [
    "#mnb = MultinomialNB()\n",
    "#model = mnb.fit(X_train, y_train)\n",
    "\n",
    "# rf = RandomForestClassifier()\n",
    "# model = rf.fit(X_train,y_train)\n",
    "\n",
    "# from xgboost import XGBClassifier\n",
    "# xgb = XGBClassifier()\n",
    "# model = xgb.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [],
   "source": [
    "# y_pred = model.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [],
   "source": [
    "# from sklearn.metrics import accuracy_score\n",
    "# score = accuracy_score(y_test, y_pred)\n",
    "# print(score)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Test code ends here"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation Accuracy: 0.9446494464944649\n"
     ]
    }
   ],
   "source": [
    "# Fitting naive bayes algorithm\n",
    "mnb = MultinomialNB()\n",
    "model = mnb.fit(X, y)\n",
    "\n",
    "# Mohit - we are taking accuracy on data on which we have trained model\n",
    "y_pred = model.predict(X)\n",
    "print(\"Validation Accuracy:\",metrics.accuracy_score(y, y_pred))\n",
    "\n",
    "with open(\"bot_model.pickle\",'wb') as f:\n",
    "    pickle.dump(model,f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation Accuracy: 0.933579335793358\n"
     ]
    }
   ],
   "source": [
    "# Xgboost predictor\n",
    "import xgboost as xgb\n",
    "from xgboost import XGBClassifier\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "\n",
    "model_xg = XGBClassifier()\n",
    "model_xg = model_xg.fit(X, y)\n",
    "y_pred = model_xg.predict(X)\n",
    "\n",
    "print(\"Validation Accuracy:\",metrics.accuracy_score(y, y_pred))\n",
    "\n",
    "with open(\"bot_model.pickle\",'wb') as f:\n",
    "    pickle.dump(model_xg,f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation Accuracy: 0.992619926199262\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\ensemble\\forest.py:245: FutureWarning: The default value of n_estimators will change from 10 in version 0.20 to 100 in 0.22.\n",
      "  \"10 in version 0.20 to 100 in 0.22.\", FutureWarning)\n"
     ]
    }
   ],
   "source": [
    "# Random forest classifier\n",
    "\n",
    "model_rf = RandomForestClassifier()\n",
    "model_rf = model_rf.fit(X, y)\n",
    "y_pred = model_rf.predict(X)\n",
    "print(\"Validation Accuracy:\",metrics.accuracy_score(y, y_pred))\n",
    "\n",
    "with open(\"bot_model.pickle\",'wb') as f:\n",
    "    pickle.dump(model_xg,f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Model building ends here"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Test code starts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Predict using model\n",
    "def process_input(s1):\n",
    "#    s1 = 'What is linear regression?'\n",
    "    s1 = cleanText(s1)\n",
    "    l1=[]\n",
    "    l1.append(s1)\n",
    "    ldf = pd.DataFrame(l1, columns= ['query'])\n",
    "    return ldf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[13]\n",
      "0.7303704533636751\n",
      "[[0.00313279 0.00313279 0.00898855 0.00464972 0.01050191 0.05785072\n",
      "  0.0542467  0.01177928 0.05514747 0.00888523 0.00310448 0.00155928\n",
      "  0.04665063 0.73037045]]\n",
      "[ 0  1  2  3  4  5  6  7  8  9 10 11 12 13]\n",
      "Sklearn\n"
     ]
    }
   ],
   "source": [
    "# Test code to be removed\n",
    "ss = 'search for library'\n",
    "query_df = process_input(ss)\n",
    "X_test     = cv.transform(query_df['query']).toarray()\n",
    "prediction = model.predict(X_test)\n",
    "prediction_proba = model.predict_proba(X_test)\n",
    "print(prediction)\n",
    "print(prediction_proba.max())\n",
    "print(prediction_proba)\n",
    "print(model.classes_)\n",
    "resp       = getResponse(prediction[0])\n",
    "print(resp)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [],
   "source": [
    "from matplotlib import pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<BarContainer object of 14 artists>"
      ]
     },
     "execution_count": 72,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.bar(model.classes_, prediction_proba[0])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Testing code end here"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Predict using model\n",
    "# def process_input(s1):\n",
    "# #    s1 = 'What is linear regression?'\n",
    "#     s1 = cleanText(s1)\n",
    "#     l1=[]\n",
    "#     l1.append(s1)\n",
    "#     ldf = pd.DataFrame(l1, columns= ['query'])\n",
    "#     return ldf\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Start of prediction flow"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Using pickle"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Trying pickle with model\n",
    "pickle_in = open('./bot_model.pickle','rb')\n",
    "classifier = pickle.load(pickle_in)\n",
    "pickle_in.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Original code to run for bot"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[31mHello. I am your machine learning assistant\n",
      "I can help you with your learning journey.\n",
      "\u001b[36mYou can ask me questions around algorithms and learn new stuff!!\n",
      "\u001b[0m\n",
      "User: what is sklearn\n",
      "Input for model:      query\n",
      "0  sklearn\n",
      "predicted value [13] with probability 0.937166154384613\n",
      "Bot:  Sklearn\n",
      "User: what liibraries can be used for ml\n",
      "Input for model:                query\n",
      "0  libraries used ml\n",
      "predicted value [13] with probability 0.7760431170463562\n",
      "Sorry I am currently not trained for this question.\n",
      "User: ok\n",
      "Input for model:   query\n",
      "0      \n",
      "predicted value [12] with probability 0.5411382913589478\n",
      "Sorry I am currently not trained for this question.\n",
      "User: thanks\n",
      "Thanks. See you again\n"
     ]
    }
   ],
   "source": [
    "# Landing message\n",
    "print(Fore.RED +  \"Hello. I am your machine learning assistant\")\n",
    "print(\"I can help you with your learning journey.\")\n",
    "print(Fore.CYAN + \"You can ask me questions around algorithms and learn new stuff!!\")\n",
    "print(Style.RESET_ALL)\n",
    "time.sleep(4)\n",
    "\n",
    "# Get input from user\n",
    "inp_text=''\n",
    "while(inp_text != 'quit'):\n",
    "    inp_text = input('User: ')\n",
    "    \n",
    "    if (inp_text in quit_words):\n",
    "        inp_text = 'quit'\n",
    "    \n",
    "    if (inp_text in greetings):\n",
    "        inp_text = 'greeting'\n",
    "        \n",
    "    if(inp_text != 'quit'):\n",
    "        if(inp_text != 'greeting'):\n",
    "            if(inp_text.lower() not in query_list):\n",
    "                store_new_query(inp_text)\n",
    "            query_df   = process_input(inp_text)\n",
    "            print(\"Input for model:\", query_df)\n",
    "            X_test     = cv.transform(query_df['query']).toarray()\n",
    "            prediction = classifier.predict(X_test)\n",
    "            max_probab = classifier.predict_proba(X_test).max()\n",
    "            print(\"predicted value {} with probability {}\".format(prediction, max_probab))\n",
    "            if (max_probab > .80):\n",
    "                resp       = getResponse(prediction[0])\n",
    "                process_response(resp)\n",
    "            else:\n",
    "                print(\"Sorry I am currently not trained for this question.\")\n",
    "        else:\n",
    "            print(\"Hello! how can I help you ?\")\n",
    "    else:\n",
    "        print(\"Thanks. See you again\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
