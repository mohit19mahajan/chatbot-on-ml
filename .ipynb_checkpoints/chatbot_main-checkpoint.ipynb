{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package punkt to\n",
      "[nltk_data]     C:\\Users\\i22166\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package punkt is already up-to-date!\n",
      "[nltk_data] Downloading package stopwords to\n",
      "[nltk_data]     C:\\Users\\i22166\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package stopwords is already up-to-date!\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "import nltk\n",
    "from nltk.stem import PorterStemmer\n",
    "## To be executed once\n",
    "# nltk.download('punkt')\n",
    "# nltk.download('stopwords')\n",
    "import re\n",
    "import pickle\n",
    "import time\n",
    "from colorama import Fore, Back, Style\n",
    "\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from sklearn.naive_bayes import MultinomialNB\n",
    "from sklearn import metrics\n",
    "\n",
    "\n",
    "import urllib.request\n",
    "import webbrowser"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "from nltk.corpus import stopwords\n",
    "#quit_words = ['quit', 'bye', 'thanks', 'exit', 'thankyou', 'thank you', 'thanku']\n",
    "# sanjay\n",
    "quit_words = ['quit', 'bye', 'thanks', 'exit', 'thankyou', 'thanku', 'goodbye', 'later', 'laters', \"sayonara\"]\n",
    "\n",
    "greetings = [\"hello\",\"hey\",\"hi\",\"hello\",\"howareyou\",\"bot\"\n",
    "                 \"howsitgoing\",\"help\",\"ineedsomehelp\",\"ineedhelp\",\n",
    "                 \"hithere\",\"hellothere\",\"hichatbot\",\"higreatlearning\",\n",
    "                 \"higreatlearning\",\"anybodythere\",\"areyouachatbot\",\n",
    "                 \"areyouhuman\",\"greetings\",\"nicetomeetyou\",\"whatsup\",\n",
    "                 \"goodmorning\",\"goodafternoon\",\"goodevening\",\n",
    "                 \"goodnight\",\"areyoureal\",\"youreamachine\",\"tellmesomething\",\n",
    "                 \"whatcanyoudo\",\"howcanyouhelpme\",\"ihaveaquestion\",\n",
    "                 \"canyouhelpme\",\"whatsyourname\",\"greetingsbot\",\"morning\",\n",
    "                 \"afternoon\",\"hellochatbot\",\"check\",\"test\",\"howdy\",\n",
    "                 \"morning\",\"afternoon\",\"evening\",\"heyman\",\"howsyourdaygoing\"\n",
    "                 \"itsbeenawhile\",\"howareyoudoing\",\"sup\",\"whatsgoingon\",\n",
    "                 \"howseverything\",\"howarethings\",\"howslife\",\"howsyourday\"\n",
    "                 \"goodtoseeyou\",\"nicetoseeyou\",\"longtimenosee\",\n",
    "                 \"pleasedtomeetyou\",\"itsnicetomeetyou\",\"howhaveyoubeen\",\n",
    "                 \"howdoyoudo\",\"yo\",\"heymate\",\"whazzup\",\"gdaymate\",\n",
    "                 \"hiya\",\"ok\",\"cool\"\n",
    "            ]\n",
    "\n",
    "fallback_messages = [\"Sorry, I don't quite understand that. Please try rephrasing your command.\",\n",
    "                     \"Oops! I didn’t get that\", \n",
    "                     \"I have never heard that before. Not sure how to respond to that.\",\n",
    "                     \"Sorry, I didn't get that. Can you say that a different way ?\",\n",
    "                     \"Sorry but I don’t know the answer to that. Try asking me something else.\",\n",
    "                     \"Sorry I am currently not trained for this question.\"]\n",
    "\n",
    "# root to be used as random state\n",
    "root = 42"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ## Spelling correction\n",
    "# import re\n",
    "# from collections import Counter\n",
    "\n",
    "# def words(text): return re.findall(r'\\w+', text.lower())\n",
    "\n",
    "# WORDS = Counter(words(open('big_ml.txt', encoding=\"utf8\").read()))\n",
    "\n",
    "# def P(word, N=sum(WORDS.values())): \n",
    "#     \"Probability of `word`.\"\n",
    "#     return WORDS[word] / N\n",
    "\n",
    "# def correction(word): \n",
    "#     \"Most probable spelling correction for word.\"\n",
    "#     return max(candidates(word), key=P)\n",
    "\n",
    "# def candidates(word): \n",
    "#     \"Generate possible spelling corrections for word.\"\n",
    "#     return (known([word]) or known(edits1(word)) or known(edits2(word)) or [word])\n",
    "\n",
    "# def known(words): \n",
    "#     \"The subset of `words` that appear in the dictionary of WORDS.\"\n",
    "#     return set(w for w in words if w in WORDS)\n",
    "\n",
    "# def edits1(word):\n",
    "#     \"All edits that are one edit away from `word`.\"\n",
    "#     letters    = 'abcdefghijklmnopqrstuvwxyz'\n",
    "#     splits     = [(word[:i], word[i:])    for i in range(len(word) + 1)]\n",
    "#     deletes    = [L + R[1:]               for L, R in splits if R]\n",
    "#     transposes = [L + R[1] + R[0] + R[2:] for L, R in splits if len(R)>1]\n",
    "#     replaces   = [L + c + R[1:]           for L, R in splits if R for c in letters]\n",
    "#     inserts    = [L + c + R               for L, R in splits for c in letters]\n",
    "#     return set(deletes + transposes + replaces + inserts)\n",
    "\n",
    "# def edits2(word): \n",
    "#     \"All edits that are two edits away from `word`.\"\n",
    "#     return (e2 for e1 in edits1(word) for e2 in edits1(e1))\n",
    "\n",
    "# def print_fallback_message(i):\n",
    "#     num_of_msgs = len(fallback_messages)\n",
    "#     idx = i % num_of_msgs\n",
    "#     print(fallback_messages[idx])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# speling correction new code\n",
    "import re, collections, math\n",
    "import re \n",
    "from collections import Counter\n",
    "\n",
    "def words(text): return re.findall('[a-z]+', text.lower())\n",
    "\n",
    "WORDS = Counter(words(open('big_ml.txt', encoding=\"utf8\").read()))\n",
    "\n",
    "def P(word, N=sum(WORDS.values())): \n",
    "    \"Probability of `word`.\"\n",
    "    return WORDS[word] / N\n",
    "\n",
    "def valid(w):\n",
    "  return all(s in WORDS for s in w.split())\n",
    "\n",
    "def correction(word): \n",
    "    \"Most probable spelling correction for word.\"\n",
    "    return max(candidates(word), key=P)\n",
    "\n",
    "def candidates(word): \n",
    "    \"Generate possible spelling corrections for word.\"\n",
    "    return (known([word]) or known(edits1(word)) or known(edits2(word)) or known(justsplit1(word)) or [word])\n",
    "\n",
    "alphabet = 'abcdefghijklmnopqrstuvwxyz '\n",
    "\n",
    "def known(words): return set(w for w in words if valid(w))\n",
    "\n",
    "def edits1(word):\n",
    "  splits     = [(word[:i], word[i:]) for i in range(len(word) + 1)]\n",
    "  deletes    = [a + b[1:] for a, b in splits if b]\n",
    "  transposes = [a + b[1] + b[0] + b[2:] for a, b in splits if len(b)>1]\n",
    "  replaces   = [a + c + b[1:] for a, b in splits for c in alphabet if b]\n",
    "  inserts    = [a + c + b     for a, b in splits for c in alphabet]\n",
    "  return set(deletes + transposes + replaces + inserts)\n",
    "\n",
    "def edits2(word): \n",
    "    \"All edits that are two edits away from `word`.\"\n",
    "    return (e2 for e1 in edits1(word) for e2 in edits1(e1))\n",
    "\n",
    "def justsplit1(word):\n",
    "    \"All edits that are one edit away from `word`.\"\n",
    "    splits     = [(word[:i], word[i:])    for i in range(len(word) + 1)]\n",
    "    #deletes    = [L + R[1:]               for L, R in splits if R]\n",
    "    deletes    = [L               for L, R in splits if R]\n",
    "    deletes1    = [R               for L, R in splits if R]\n",
    "    return set(deletes + deletes1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Common functions definition\n",
    "\n",
    "def cleanText(s1):\n",
    "#    print(\"Inside cleanText for:\", s1)  ##debug\n",
    "    ps = PorterStemmer()\n",
    "    text = s1.lower()\n",
    "    text = re.sub(r'[0-9]*','',text)\n",
    "    text = re.sub(r'^([a-z],[A-Z])*','',text)\n",
    "    text = re.sub(r'\\s\\s+',' ',text)\n",
    "    word_list = []\n",
    "    for word in nltk.word_tokenize(text):\n",
    "        \n",
    "#        print(\"Original word:\", word)  ## debug print\n",
    "        word = correction(word)\n",
    "#        print(\"corrected word:\", word)  ##debug print\n",
    "        if(word not in stopwords.words('english')):\n",
    "            ps.stem(word)\n",
    "            word_list.append(word)\n",
    "    text = word_list\n",
    "#    print('from clean text:', word_list)  ## debug\n",
    "### Removed below line after adding code for spelling correction\n",
    "#    text = [ps.stem(word) for word in nltk.word_tokenize(text) if word not in stopwords.words('english')]\n",
    "    text = ' '.join(text)\n",
    "#    print(\"Final sentence:\", text)  ## debug print\n",
    "#    print(\"Returning string from cleanText is:\", text)  ##debug\n",
    "    return text\n",
    "\n",
    "# After prediction convert tag to response\n",
    "def getResponse(tag):\n",
    "    try:\n",
    "        if(resp_dict[tag]):\n",
    "            response = resp_dict[tag]\n",
    "            return response\n",
    "        else:\n",
    "            print('Response not found.. Please try another query.')\n",
    "    except:\n",
    "        print('Response not found for:', tag)\n",
    "        print('I will update my knowledge soon :)')\n",
    "\n",
    "def process_response(response):\n",
    "    if(response[0:4]=='Link'):\n",
    "        url = response[5:]\n",
    "#        webbrowser.open(url)\n",
    "        print(\"Bot: url to open is {}\".format(url))\n",
    "    else:\n",
    "        print(\"Bot: \", response)\n",
    "\n",
    "def store_new_query(query):\n",
    "#    print(\"Inside store_new_query function\")  ##debug\n",
    "    with open(\"non_corpus_queries.txt\", \"a\") as f:\n",
    "        str = inp_text + \"\\n\"\n",
    "        f.write(str)\n",
    "#SANJAY\n",
    "def clean_greeting(user_input: str):\n",
    "#    print(\"Inside clean_greeting function:\", user_input)  ##debug\n",
    "    cleaned_word = cleanText(user_input)\n",
    "    remove_spl_char = ''.join(e for e in cleaned_word if e.isalnum())\n",
    "    return ''.join([i for i in remove_spl_char if not i.isdigit()]) \n",
    "\n",
    "def print_fallback_message(i): \n",
    "    num_of_msgs = len(fallback_messages) \n",
    "    idx = i % num_of_msgs \n",
    "    print(fallback_messages[idx])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv(\"Corpus_1.csv\")\n",
    "df.columns = ['query', 'response', 'tag']\n",
    "df = df.dropna()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>query</th>\n",
       "      <th>response</th>\n",
       "      <th>tag</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>0</td>\n",
       "      <td>What is linear regression</td>\n",
       "      <td>Link:https://en.wikipedia.org/wiki/Linear_regr...</td>\n",
       "      <td>Linear regression</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>Can you explain linear regression</td>\n",
       "      <td>Link:https://en.wikipedia.org/wiki/Linear_regr...</td>\n",
       "      <td>Linear regression</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                               query  \\\n",
       "0          What is linear regression   \n",
       "1  Can you explain linear regression   \n",
       "\n",
       "                                            response                tag  \n",
       "0  Link:https://en.wikipedia.org/wiki/Linear_regr...  Linear regression  \n",
       "1  Link:https://en.wikipedia.org/wiki/Linear_regr...  Linear regression  "
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['transformed_query'] = df['query'].apply(cleanText)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Preparing list of queries to compare to later to store new queries\n",
    "query_list = df['query'].tolist()\n",
    "query_list = [i.lower() for i in query_list]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "# encoding the target column\n",
    "le = LabelEncoder()\n",
    "df['tag_encoded'] = le.fit_transform(df['tag'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Converting with bag of words\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "cv = CountVectorizer(ngram_range=(1, 2))\n",
    "X = cv.fit_transform(df['transformed_query']).toarray()\n",
    "\n",
    "y = df['tag_encoded']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Creating dataframe to visualize data\n",
    "temp_name = cv.get_feature_names()\n",
    "temp = pd.DataFrame(X, columns=temp_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create dictionary for tag to response\n",
    "temp = df[['tag_encoded', 'response']]\n",
    "temp = temp.groupby(['tag_encoded']).max()\n",
    "resp_dict = temp.to_dict()\n",
    "resp_dict = resp_dict['response']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Test code"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Test code to check accuracy\n",
    "# from sklearn.model_selection import train_test_split\n",
    "# X_train, X_test, y_train, y_test = train_test_split(X, y, test_size = 0.3, random_state = root)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "# from sklearn.naive_bayes import MultinomialNB\n",
    "# from sklearn.ensemble import RandomForestClassifier\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "#mnb = MultinomialNB()\n",
    "#model = mnb.fit(X_train, y_train)\n",
    "\n",
    "# rf = RandomForestClassifier()\n",
    "# model = rf.fit(X_train,y_train)\n",
    "\n",
    "# from xgboost import XGBClassifier\n",
    "# xgb = XGBClassifier()\n",
    "# model = xgb.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "# y_pred = model.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "# from sklearn.metrics import accuracy_score\n",
    "# score = accuracy_score(y_test, y_pred)\n",
    "# print(score)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_file = pd.read_csv('test_set.csv')\n",
    "#test_file = pd.read_csv('gl_test_data.csv')\n",
    "test_file.columns = ['query', 'tag']\n",
    "Xt1 = cv.transform(test_file['query']).toarray()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [],
   "source": [
    "# le1 = le.fit(df['tag'])\n",
    "# df['tag_encoded'] = le1.transform(df['tag'])\n",
    "\n",
    "yt1 = le.transform(test_file['tag'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test File Accuracy 0.9241379310344827\n"
     ]
    }
   ],
   "source": [
    "# for testing accuracy of the test set\n",
    "import xgboost as xgb\n",
    "from xgboost import XGBClassifier\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "\n",
    "model_xg = XGBClassifier(seed = 10)\n",
    "model_xg = model_xg.fit(X, y)\n",
    "y_pred_xg = model_xg.predict(Xt1)\n",
    "\n",
    "print(\"Test File Accuracy\",metrics.accuracy_score(yt1, y_pred_xg))\n",
    "\n",
    "with open(\"bot_model.pickle\",'wb') as f:\n",
    "    pickle.dump(model_xg,f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Test code ends here"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation Accuracy: 0.9592198581560284\n"
     ]
    }
   ],
   "source": [
    "# # Fitting naive bayes algorithm\n",
    "# mnb = MultinomialNB()\n",
    "# model = mnb.fit(X, y)\n",
    "\n",
    "# # Mohit - we are taking accuracy on data on which we have trained model\n",
    "# y_pred = model.predict(X)\n",
    "# print(\"Validation Accuracy:\",metrics.accuracy_score(y, y_pred))\n",
    "\n",
    "# with open(\"bot_model.pickle\",'wb') as f:\n",
    "#     pickle.dump(model,f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation Accuracy: 0.9521276595744681\n"
     ]
    }
   ],
   "source": [
    "# Xgboost predictor\n",
    "import xgboost as xgb\n",
    "from xgboost import XGBClassifier\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "\n",
    "model_xg = XGBClassifier()\n",
    "model_xg = model_xg.fit(X, y)\n",
    "y_pred = model_xg.predict(X)\n",
    "\n",
    "print(\"Validation Accuracy:\",metrics.accuracy_score(y, y_pred))\n",
    "\n",
    "with open(\"bot_model.pickle\",'wb') as f:\n",
    "    pickle.dump(model_xg,f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation Accuracy: 0.9929078014184397\n"
     ]
    }
   ],
   "source": [
    "# # Random forest classifier\n",
    "\n",
    "# model_rf = RandomForestClassifier()\n",
    "# model_rf = model_rf.fit(X, y)\n",
    "# y_pred = model_rf.predict(X)\n",
    "# print(\"Validation Accuracy:\",metrics.accuracy_score(y, y_pred))\n",
    "\n",
    "# with open(\"bot_model.pickle\",'wb') as f:\n",
    "#     pickle.dump(model_xg,f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Model building ends here"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Test code starts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Predict using model\n",
    "def process_input(s1):\n",
    "#    s1 = 'What is linear regression?'\n",
    "    s1 = cleanText(s1)\n",
    "    l1=[]\n",
    "    l1.append(s1)\n",
    "    ldf = pd.DataFrame(l1, columns= ['query'])\n",
    "    return ldf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[22]\n",
      "0.6097642757616746\n",
      "[[0.0131619  0.01552399 0.03295138 0.0107674  0.03308222 0.0138275\n",
      "  0.01229275 0.03599765 0.03604786 0.01003861 0.00345251 0.03668115\n",
      "  0.01416683 0.03814083 0.0067548  0.00755805 0.00996192 0.00600849\n",
      "  0.00345251 0.00513796 0.01000779 0.02535021 0.60976428 0.00987142]]\n",
      "[ 0  1  2  3  4  5  6  7  8  9 10 11 12 13 14 15 16 17 18 19 20 21 22 23]\n",
      "Link: https://en.wikipedia.org/wiki/Scikit-learn\n"
     ]
    }
   ],
   "source": [
    "# Test code to be removed\n",
    "ss = 'search for library'\n",
    "query_df = process_input(ss)\n",
    "X_test     = cv.transform(query_df['query']).toarray()\n",
    "prediction = model.predict(X_test)\n",
    "prediction_proba = model.predict_proba(X_test)\n",
    "print(prediction)\n",
    "print(prediction_proba.max())\n",
    "print(prediction_proba)\n",
    "print(model.classes_)\n",
    "resp       = getResponse(prediction[0])\n",
    "print(resp)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "from matplotlib import pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<BarContainer object of 24 artists>"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.bar(model.classes_, prediction_proba[0])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Testing code end here"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Predict using model\n",
    "# def process_input(s1):\n",
    "# #    s1 = 'What is linear regression?'\n",
    "#     s1 = cleanText(s1)\n",
    "#     l1=[]\n",
    "#     l1.append(s1)\n",
    "#     ldf = pd.DataFrame(l1, columns= ['query'])\n",
    "#     return ldf\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Start of prediction flow"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Using pickle"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Trying pickle with model\n",
    "pickle_in = open('./bot_model.pickle','rb')\n",
    "classifier = pickle.load(pickle_in)\n",
    "pickle_in.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Original code to run for bot"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[31mHello. I am your machine learning assistant\n",
      "I can help you with your learning journey.\n",
      "\u001b[36mYou can ask me questions around algorithms and learn new stuff!!\n",
      "\u001b[0m\n",
      "User: what is machine learning\n",
      "Input for model:               query\n",
      "0  machine learning\n",
      "predicted value [10] with probability 0.47853291034698486\n",
      "Sorry, I don't quite understand that. Please try rephrasing your command.\n",
      "User: ok bye\n",
      "Input for model:     query\n",
      "0  ok bye\n",
      "predicted value [21] with probability 0.4036799669265747\n",
      "Oops! I didn’t get that\n",
      "User: bye\n",
      "Thanks. See you again\n"
     ]
    }
   ],
   "source": [
    "# Landing message\n",
    "print(Fore.RED +  \"Hello. I am your machine learning assistant\")\n",
    "print(\"I can help you with your learning journey.\")\n",
    "print(Fore.CYAN + \"You can ask me questions around algorithms and learn new stuff!!\")\n",
    "print(Style.RESET_ALL)\n",
    "time.sleep(4)\n",
    "\n",
    "# Get input from user\n",
    "inp_text=''\n",
    "i = 0\n",
    "context = 'predict'\n",
    "\n",
    "while(context != 'quit'):\n",
    "    context = 'predict'\n",
    "    inp_text = input('User: ')\n",
    "    \n",
    "### Sanjay\n",
    "#    print(\"Cleaned text:\", clean_greeting(inp_text))  ## debug\n",
    "    if (clean_greeting(inp_text) in quit_words):\n",
    "        context = 'quit'\n",
    "#    print(\"After checking quit words\", inp_text)  ##debug\n",
    "\n",
    "### Sanjay\n",
    "    if (clean_greeting(inp_text) in greetings):\n",
    "#         print(\"Setting context to greeting\")  ##debug\n",
    "        context = 'greeting'\n",
    "    \n",
    "#     print(\"After checking greeting words:\", inp_text)  ##debug\n",
    "#     print(\"1111 context: {} and input {}\".format(context, inp_text))    ##debug\n",
    "\n",
    "    if(context != 'quit'):\n",
    "        if(context != 'greeting'):\n",
    "            if(inp_text.lower() not in query_list):\n",
    "                store_new_query(inp_text)\n",
    "            query_df   = process_input(inp_text)\n",
    "            print(\"Input for model:\", query_df)\n",
    "            X_test     = cv.transform(query_df['query']).toarray()\n",
    "            prediction = classifier.predict(X_test)\n",
    "            max_probab = classifier.predict_proba(X_test).max()\n",
    "            print(\"predicted value {} with probability {}\".format(prediction, max_probab))   ##debug\n",
    "            if (max_probab > .60):\n",
    "                resp       = getResponse(prediction[0])\n",
    "                process_response(resp)\n",
    "            else:\n",
    "                print_fallback_message(i)\n",
    "                i = i + 1\n",
    "        else:\n",
    "            if(inp_text.lower() in ['ok','cool']):\n",
    "                print(\"I am glad to assist you. You can ask me other questions.\")\n",
    "            else:\n",
    "                print(\"Hello! how can I help you ?\")\n",
    "    else:\n",
    "        print(\"Thanks. See you again\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# In case of bbye cleanText is returning empty string"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
