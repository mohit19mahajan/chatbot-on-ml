{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "import nltk\n",
    "from nltk.stem import PorterStemmer\n",
    "import re\n",
    "import pickle\n",
    "import time\n",
    "from colorama import Fore, Back, Style\n",
    "\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from sklearn.naive_bayes import MultinomialNB\n",
    "from sklearn import metrics\n",
    "\n",
    "\n",
    "import urllib.request\n",
    "import webbrowser"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from nltk.corpus import stopwords\n",
    "#quit_words = ['quit', 'bye', 'thanks', 'exit', 'thankyou', 'thank you', 'thanku']\n",
    "# sanjay\n",
    "quit_words = ['quit', 'bye', 'thanks', 'exit', 'thankyou', 'thanku', 'goodbye', 'later', 'laters', \"sayonara\"]\n",
    "\n",
    "greetings = [\"hello\",\"hey\",\"hi\",\"hello\",\"howareyou\",\"bot\"\n",
    "                 \"howsitgoing\",\"help\",\"ineedsomehelp\",\"ineedhelp\",\n",
    "                 \"hithere\",\"hellothere\",\"hichatbot\",\"higreatlearning\",\n",
    "                 \"higreatlearning\",\"anybodythere\",\"areyouachatbot\",\n",
    "                 \"areyouhuman\",\"greetings\",\"nicetomeetyou\",\"whatsup\",\n",
    "                 \"goodmorning\",\"goodafternoon\",\"goodevening\",\n",
    "                 \"goodnight\",\"areyoureal\",\"youreamachine\",\"tellmesomething\",\n",
    "                 \"whatcanyoudo\",\"howcanyouhelpme\",\"ihaveaquestion\",\n",
    "                 \"canyouhelpme\",\"whatsyourname\",\"greetingsbot\",\"morning\",\n",
    "                 \"afternoon\",\"hellochatbot\",\"check\",\"test\",\"howdy\",\n",
    "                 \"morning\",\"afternoon\",\"evening\",\"heyman\",\"howsyourdaygoing\"\n",
    "                 \"itsbeenawhile\",\"howareyoudoing\",\"sup\",\"whatsgoingon\",\n",
    "                 \"howseverything\",\"howarethings\",\"howslife\",\"howsyourday\"\n",
    "                 \"goodtoseeyou\",\"nicetoseeyou\",\"longtimenosee\",\n",
    "                 \"pleasedtomeetyou\",\"itsnicetomeetyou\",\"howhaveyoubeen\",\n",
    "                 \"howdoyoudo\",\"yo\",\"heymate\",\"whazzup\",\"gdaymate\",\n",
    "                 \"hiya\",\"ok\",\"cool\"\n",
    "            ]\n",
    "\n",
    "fallback_messages = [\"Sorry, I don't quite understand that. Please try rephrasing your command.\",\n",
    "                     \"Oops! I didn’t get that\", \n",
    "                     \"I have never heard that before. Not sure how to respond to that.\",\n",
    "                     \"Sorry, I didn't get that. Can you say that a different way ?\",\n",
    "                     \"Sorry but I don’t know the answer to that. Try asking me something else.\",\n",
    "                     \"Sorry I am currently not trained for this question.\"]\n",
    "\n",
    "# root to be used as random state\n",
    "root = 42"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Spelling correction\n",
    "import re\n",
    "from collections import Counter\n",
    "\n",
    "def words(text): return re.findall(r'\\w+', text.lower())\n",
    "\n",
    "WORDS = Counter(words(open('big_ml.txt', encoding=\"utf8\").read()))\n",
    "\n",
    "def P(word, N=sum(WORDS.values())): \n",
    "    \"Probability of `word`.\"\n",
    "    return WORDS[word] / N\n",
    "\n",
    "def correction(word): \n",
    "    \"Most probable spelling correction for word.\"\n",
    "    return max(candidates(word), key=P)\n",
    "\n",
    "def candidates(word): \n",
    "    \"Generate possible spelling corrections for word.\"\n",
    "    return (known([word]) or known(edits1(word)) or known(edits2(word)) or [word])\n",
    "\n",
    "def known(words): \n",
    "    \"The subset of `words` that appear in the dictionary of WORDS.\"\n",
    "    return set(w for w in words if w in WORDS)\n",
    "\n",
    "def edits1(word):\n",
    "    \"All edits that are one edit away from `word`.\"\n",
    "    letters    = 'abcdefghijklmnopqrstuvwxyz'\n",
    "    splits     = [(word[:i], word[i:])    for i in range(len(word) + 1)]\n",
    "    deletes    = [L + R[1:]               for L, R in splits if R]\n",
    "    transposes = [L + R[1] + R[0] + R[2:] for L, R in splits if len(R)>1]\n",
    "    replaces   = [L + c + R[1:]           for L, R in splits if R for c in letters]\n",
    "    inserts    = [L + c + R               for L, R in splits for c in letters]\n",
    "    return set(deletes + transposes + replaces + inserts)\n",
    "\n",
    "def edits2(word): \n",
    "    \"All edits that are two edits away from `word`.\"\n",
    "    return (e2 for e1 in edits1(word) for e2 in edits1(e1))\n",
    "\n",
    "def print_fallback_message(i):\n",
    "    num_of_msgs = len(fallback_messages)\n",
    "    idx = i % num_of_msgs\n",
    "    print(fallback_messages[idx])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Common functions definition\n",
    "\n",
    "def cleanText(s1):\n",
    "#    print(\"Inside cleanText for:\", s1)  ##debug\n",
    "    ps = PorterStemmer()\n",
    "    text = s1.lower()\n",
    "    text = re.sub(r'[0-9]*','',text)\n",
    "    text = re.sub(r'^([a-z],[A-Z])*','',text)\n",
    "    text = re.sub(r'\\s\\s+',' ',text)\n",
    "    word_list = []\n",
    "    for word in nltk.word_tokenize(text):\n",
    "        \n",
    "#        print(\"Original word:\", word)  ## debug print\n",
    "        word = correction(word)\n",
    "#        print(\"corrected word:\", word)  ##debug print\n",
    "        if(word not in stopwords.words('english')):\n",
    "            ps.stem(word)\n",
    "            word_list.append(word)\n",
    "    text = word_list\n",
    "#    print('from clean text:', word_list)  ## debug\n",
    "### Removed below line after adding code for spelling correction\n",
    "#    text = [ps.stem(word) for word in nltk.word_tokenize(text) if word not in stopwords.words('english')]\n",
    "    text = ' '.join(text)\n",
    "#    print(\"Final sentence:\", text)  ## debug print\n",
    "#    print(\"Returning string from cleanText is:\", text)  ##debug\n",
    "    return text\n",
    "\n",
    "# After prediction convert tag to response\n",
    "def getResponse(tag):\n",
    "    try:\n",
    "        if(resp_dict[tag]):\n",
    "            response = resp_dict[tag]\n",
    "            return response\n",
    "        else:\n",
    "            print('Response not found.. Please try another query.')\n",
    "    except:\n",
    "        print('Response not found for:', tag)\n",
    "        print('I will update my knowledge soon :)')\n",
    "\n",
    "def process_response(response):\n",
    "    if(response[0:4]=='Link'):\n",
    "        url = response[5:]\n",
    "#        webbrowser.open(url)\n",
    "        print(\"Bot: url to open is {}\".format(url))\n",
    "    else:\n",
    "        print(\"Bot: \", response)\n",
    "\n",
    "def store_new_query(query):\n",
    "#    print(\"Inside store_new_query function\")  ##debug\n",
    "    with open(\"non_corpus_queries.txt\", \"a\") as f:\n",
    "        str = inp_text + \"\\n\"\n",
    "        f.write(str)\n",
    "#SANJAY\n",
    "def clean_greeting(user_input: str):\n",
    "#    print(\"Inside clean_greeting function:\", user_input)  ##debug\n",
    "    cleaned_word = cleanText(user_input)\n",
    "    remove_spl_char = ''.join(e for e in cleaned_word if e.isalnum())\n",
    "    return ''.join([i for i in remove_spl_char if not i.isdigit()]) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv(\"Corpus_1.csv\")\n",
    "df.columns = ['query', 'response', 'tag']\n",
    "df = df.dropna()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>query</th>\n",
       "      <th>response</th>\n",
       "      <th>tag</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>0</td>\n",
       "      <td>What is linear regression</td>\n",
       "      <td>Link:https://en.wikipedia.org/wiki/Linear_regr...</td>\n",
       "      <td>Linear regression</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>Can you explain linear regression</td>\n",
       "      <td>Link:https://en.wikipedia.org/wiki/Linear_regr...</td>\n",
       "      <td>Linear regression</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                               query  \\\n",
       "0          What is linear regression   \n",
       "1  Can you explain linear regression   \n",
       "\n",
       "                                            response                tag  \n",
       "0  Link:https://en.wikipedia.org/wiki/Linear_regr...  Linear regression  \n",
       "1  Link:https://en.wikipedia.org/wiki/Linear_regr...  Linear regression  "
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['transformed_query'] = df['query'].apply(cleanText)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Preparing list of queries to compare to later to store new queries\n",
    "query_list = df['query'].tolist()\n",
    "query_list = [i.lower() for i in query_list]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# encoding the target column\n",
    "le = LabelEncoder()\n",
    "df['tag_encoded'] = le.fit_transform(df['tag'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Converting with bag of words\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "cv = CountVectorizer(ngram_range=(1, 2))\n",
    "X = cv.fit_transform(df['transformed_query']).toarray()\n",
    "\n",
    "y = df['tag_encoded']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Creating dataframe to visualize data\n",
    "temp_name = cv.get_feature_names()\n",
    "temp = pd.DataFrame(X, columns=temp_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create dictionary for tag to response\n",
    "temp = df[['tag_encoded', 'response']]\n",
    "temp = temp.groupby(['tag_encoded']).max()\n",
    "resp_dict = temp.to_dict()\n",
    "resp_dict = resp_dict['response']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Test code"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Test code to check accuracy\n",
    "# from sklearn.model_selection import train_test_split\n",
    "# X_train, X_test, y_train, y_test = train_test_split(X, y, test_size = 0.3, random_state = root)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "# from sklearn.naive_bayes import MultinomialNB\n",
    "# from sklearn.ensemble import RandomForestClassifier\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "#mnb = MultinomialNB()\n",
    "#model = mnb.fit(X_train, y_train)\n",
    "\n",
    "# rf = RandomForestClassifier()\n",
    "# model = rf.fit(X_train,y_train)\n",
    "\n",
    "# from xgboost import XGBClassifier\n",
    "# xgb = XGBClassifier()\n",
    "# model = xgb.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "# y_pred = model.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "# from sklearn.metrics import accuracy_score\n",
    "# score = accuracy_score(y_test, y_pred)\n",
    "# print(score)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Test code ends here"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation Accuracy: 0.9543057996485061\n"
     ]
    }
   ],
   "source": [
    "# Fitting naive bayes algorithm\n",
    "mnb = MultinomialNB()\n",
    "model = mnb.fit(X, y)\n",
    "\n",
    "# Mohit - we are taking accuracy on data on which we have trained model\n",
    "y_pred = model.predict(X)\n",
    "print(\"Validation Accuracy:\",metrics.accuracy_score(y, y_pred))\n",
    "\n",
    "with open(\"bot_model.pickle\",'wb') as f:\n",
    "    pickle.dump(model,f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation Accuracy: 0.9420035149384886\n"
     ]
    }
   ],
   "source": [
    "# Xgboost predictor\n",
    "import xgboost as xgb\n",
    "from xgboost import XGBClassifier\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "\n",
    "model_xg = XGBClassifier()\n",
    "model_xg = model_xg.fit(X, y)\n",
    "y_pred = model_xg.predict(X)\n",
    "\n",
    "print(\"Validation Accuracy:\",metrics.accuracy_score(y, y_pred))\n",
    "\n",
    "with open(\"bot_model.pickle\",'wb') as f:\n",
    "    pickle.dump(model_xg,f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation Accuracy: 0.9859402460456942\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\ensemble\\forest.py:245: FutureWarning: The default value of n_estimators will change from 10 in version 0.20 to 100 in 0.22.\n",
      "  \"10 in version 0.20 to 100 in 0.22.\", FutureWarning)\n"
     ]
    }
   ],
   "source": [
    "# Random forest classifier\n",
    "\n",
    "model_rf = RandomForestClassifier()\n",
    "model_rf = model_rf.fit(X, y)\n",
    "y_pred = model_rf.predict(X)\n",
    "print(\"Validation Accuracy:\",metrics.accuracy_score(y, y_pred))\n",
    "\n",
    "with open(\"bot_model.pickle\",'wb') as f:\n",
    "    pickle.dump(model_xg,f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Model building ends here"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Test code starts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Predict using model\n",
    "def process_input(s1):\n",
    "#    s1 = 'What is linear regression?'\n",
    "    s1 = cleanText(s1)\n",
    "    l1=[]\n",
    "    l1.append(s1)\n",
    "    ldf = pd.DataFrame(l1, columns= ['query'])\n",
    "    return ldf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[22]\n",
      "0.6067727981406362\n",
      "[[0.01311884 0.01390663 0.0329007  0.01073348 0.03294498 0.01380055\n",
      "  0.01225172 0.03582382 0.0358888  0.01000877 0.0075599  0.03656374\n",
      "  0.01412375 0.0378908  0.00753611 0.00753611 0.01013587 0.00682222\n",
      "  0.00344423 0.00512488 0.00997749 0.02527948 0.6067728  0.00985432]]\n",
      "[ 0  1  2  3  4  5  6  7  8  9 10 11 12 13 14 15 16 17 18 19 20 21 22 23]\n",
      "Sklearn\n"
     ]
    }
   ],
   "source": [
    "# Test code to be removed\n",
    "ss = 'search for library'\n",
    "query_df = process_input(ss)\n",
    "X_test     = cv.transform(query_df['query']).toarray()\n",
    "prediction = model.predict(X_test)\n",
    "prediction_proba = model.predict_proba(X_test)\n",
    "print(prediction)\n",
    "print(prediction_proba.max())\n",
    "print(prediction_proba)\n",
    "print(model.classes_)\n",
    "resp       = getResponse(prediction[0])\n",
    "print(resp)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "from matplotlib import pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<BarContainer object of 24 artists>"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.bar(model.classes_, prediction_proba[0])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Testing code end here"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Predict using model\n",
    "# def process_input(s1):\n",
    "# #    s1 = 'What is linear regression?'\n",
    "#     s1 = cleanText(s1)\n",
    "#     l1=[]\n",
    "#     l1.append(s1)\n",
    "#     ldf = pd.DataFrame(l1, columns= ['query'])\n",
    "#     return ldf\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Start of prediction flow"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Using pickle"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Trying pickle with model\n",
    "pickle_in = open('./bot_model.pickle','rb')\n",
    "classifier = pickle.load(pickle_in)\n",
    "pickle_in.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Original code to run for bot"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[31mHello. I am your machine learning assistant\n",
      "I can help you with your learning journey.\n",
      "\u001b[36mYou can ask me questions around algorithms and learn new stuff!!\n",
      "\u001b[0m\n",
      "User: hello\n",
      "Cleaned text: hello\n",
      "Hello! how can I help you ?\n",
      "User: what is machine learning\n",
      "Cleaned text: machinelearning\n",
      "Input for model:               query\n",
      "0  machine learning\n",
      "Bot:  Supervised Learning, Unsupervised Learning, Ensemble Techniques, Featurization, Model Selection & Tuning\n",
      "User: bye\n",
      "Cleaned text: bye\n",
      "Thanks. See you again\n"
     ]
    }
   ],
   "source": [
    "# Landing message\n",
    "print(Fore.RED +  \"Hello. I am your machine learning assistant\")\n",
    "print(\"I can help you with your learning journey.\")\n",
    "print(Fore.CYAN + \"You can ask me questions around algorithms and learn new stuff!!\")\n",
    "print(Style.RESET_ALL)\n",
    "time.sleep(4)\n",
    "\n",
    "# Get input from user\n",
    "inp_text=''\n",
    "i = 0\n",
    "context = 'predict'\n",
    "\n",
    "while(context != 'quit'):\n",
    "    context = 'predict'\n",
    "    inp_text = input('User: ')\n",
    "    \n",
    "### Sanjay\n",
    "#    print(\"Cleaned text:\", clean_greeting(inp_text))  ## debug\n",
    "    if (clean_greeting(inp_text) in quit_words):\n",
    "        context = 'quit'\n",
    "#    print(\"After checking quit words\", inp_text)  ##debug\n",
    "\n",
    "### Sanjay\n",
    "    if (clean_greeting(inp_text) in greetings):\n",
    "#         print(\"Setting context to greeting\")  ##debug\n",
    "        context = 'greeting'\n",
    "    \n",
    "#     print(\"After checking greeting words:\", inp_text)  ##debug\n",
    "#     print(\"1111 context: {} and input {}\".format(context, inp_text))    ##debug\n",
    "\n",
    "    if(context != 'quit'):\n",
    "        if(context != 'greeting'):\n",
    "            if(inp_text.lower() not in query_list):\n",
    "                store_new_query(inp_text)\n",
    "            query_df   = process_input(inp_text)\n",
    "            print(\"Input for model:\", query_df)\n",
    "            X_test     = cv.transform(query_df['query']).toarray()\n",
    "            prediction = classifier.predict(X_test)\n",
    "            max_probab = classifier.predict_proba(X_test).max()\n",
    "#             print(\"predicted value {} with probability {}\".format(prediction, max_probab))   ##debug\n",
    "            if (max_probab > .60):\n",
    "                resp       = getResponse(prediction[0])\n",
    "                process_response(resp)\n",
    "            else:\n",
    "                print_fallback_message(i)\n",
    "                i = i + 1\n",
    "        else:\n",
    "            if(inp_text.lower() in ['ok','cool']):\n",
    "                print(\"I am glad to assist you. You can ask me other questions.\")\n",
    "            else:\n",
    "                print(\"Hello! how can I help you ?\")\n",
    "    else:\n",
    "        print(\"Thanks. See you again\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "# In case of bbye cleanText is returning empty string"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
